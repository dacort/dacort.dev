<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>An Introduction to Modern Data Lake Storage Layers | Damon Cortesi</title><meta name=keywords content="aws,apache,hudi,iceberg,deltalake"><meta name=description content="In recent years we&rsquo;ve seen a rise in new storage layers for data lakes. In 2017, Uber announced Hudi - an incremental processing framework for data pipelines. In 2018, Netflix introduced Iceberg - a new table format for managing extremely large cloud datasets. And in 2019, Databricks open-sourced Delta Lake - originally intended to bring ACID transactions to data lakes.
 📹 If you&rsquo;d like to watch a video that discusses the content of this post, I&rsquo;ve also recorded an overview here."><meta name=author content><link rel=canonical href=https://dacort.dev/posts/modern-data-lake-storage-layers/><link crossorigin=anonymous href=/assets/css/stylesheet.min.640768aec184f5d7657b498b44c1649aeeac390be208b1077640933543054b77.css integrity="sha256-ZAdorsGE9ddle0mLRMFkmu6sOQviCLEHdkCTNUMFS3c=" rel="preload stylesheet" as=style><link rel=preload href=/images/dacort.jpeg as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://dacort.dev/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dacort.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dacort.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://dacort.dev/apple-touch-icon.png><link rel=mask-icon href=https://dacort.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><meta property="og:title" content="An Introduction to Modern Data Lake Storage Layers"><meta property="og:description" content="In recent years we&rsquo;ve seen a rise in new storage layers for data lakes. In 2017, Uber announced Hudi - an incremental processing framework for data pipelines. In 2018, Netflix introduced Iceberg - a new table format for managing extremely large cloud datasets. And in 2019, Databricks open-sourced Delta Lake - originally intended to bring ACID transactions to data lakes.
 📹 If you&rsquo;d like to watch a video that discusses the content of this post, I&rsquo;ve also recorded an overview here."><meta property="og:type" content="article"><meta property="og:url" content="https://dacort.dev/posts/modern-data-lake-storage-layers/"><meta property="og:image" content="https://dacort.dev/posts/modern-data-lake-storage-layers/lake.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-02-02T14:22:22-08:00"><meta property="article:modified_time" content="2022-02-02T14:22:22-08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dacort.dev/posts/modern-data-lake-storage-layers/lake.jpg"><meta name=twitter:title content="An Introduction to Modern Data Lake Storage Layers"><meta name=twitter:description content="In recent years we&rsquo;ve seen a rise in new storage layers for data lakes. In 2017, Uber announced Hudi - an incremental processing framework for data pipelines. In 2018, Netflix introduced Iceberg - a new table format for managing extremely large cloud datasets. And in 2019, Databricks open-sourced Delta Lake - originally intended to bring ACID transactions to data lakes.
 📹 If you&rsquo;d like to watch a video that discusses the content of this post, I&rsquo;ve also recorded an overview here."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dacort.dev/posts/"},{"@type":"ListItem","position":2,"name":"An Introduction to Modern Data Lake Storage Layers","item":"https://dacort.dev/posts/modern-data-lake-storage-layers/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"An Introduction to Modern Data Lake Storage Layers","name":"An Introduction to Modern Data Lake Storage Layers","description":"In recent years we\u0026rsquo;ve seen a rise in new storage layers for data lakes. In 2017, Uber announced Hudi - an incremental processing framework for data pipelines. In 2018, Netflix introduced Iceberg - a new table format for managing extremely large cloud datasets. And in 2019, Databricks open-sourced Delta Lake - originally intended to bring ACID transactions to data lakes.\n 📹 If you\u0026rsquo;d like to watch a video that discusses the content of this post, I\u0026rsquo;ve also recorded an overview here.","keywords":["aws","apache","hudi","iceberg","deltalake"],"articleBody":"In recent years we’ve seen a rise in new storage layers for data lakes. In 2017, Uber announced Hudi - an incremental processing framework for data pipelines. In 2018, Netflix introduced Iceberg - a new table format for managing extremely large cloud datasets. And in 2019, Databricks open-sourced Delta Lake - originally intended to bring ACID transactions to data lakes.\n 📹 If you’d like to watch a video that discusses the content of this post, I’ve also recorded an overview here. Each relevant section below will also link to individual timestamps.\n This post aims to introduce each of these engines and give some insight into how they function under the hood and some of the differences in each. While I’ll summarize the findings here, you can also view my Jupyter notebooks for each in my modern-data-lake-storage-layers repository. We begin with basic operations of writing and updating datasets.\nOne thing to note about all of these frameworks is that each began with a different challenge they were solving for, but over time they have begun to converge on a common set of functionality.\nApache Hudi  📹 Intro to Apache Hudi video\n Apache Hudi (Hadoop Upsert Delete and Incremental) was originally designed as an incremental stream processing framework and was built to combine the benefits of stream and batch processing. Hudi can be used with Spark, Flink, Presto, Trino and Hive, but much of the original work was focused around Spark and that’s what I use for these examples.\nFor Hudi, we create a simple Spark DataFrame partitioned by creation_date and write that to S3.\n# Create a DataFrame inputDF = spark.createDataFrame( [ (\"100\", \"2015-01-01\", \"2015-01-01T13:51:39.340396Z\"), (\"101\", \"2015-01-01\", \"2015-01-01T12:14:58.597216Z\"), (\"102\", \"2015-01-01\", \"2015-01-01T13:51:40.417052Z\"), (\"103\", \"2015-01-01\", \"2015-01-01T13:51:40.519832Z\"), (\"104\", \"2015-01-02\", \"2015-01-01T12:15:00.512679Z\"), (\"105\", \"2015-01-02\", \"2015-01-01T13:51:42.248818Z\"), ], [\"id\", \"creation_date\", \"last_update_time\"], ) # Specify common DataSourceWriteOptions in the single hudiOptions variable hudiOptions = { \"hoodie.table.name\": \"my_hudi_table\", \"hoodie.datasource.write.recordkey.field\": \"id\", \"hoodie.datasource.write.partitionpath.field\": \"creation_date\", \"hoodie.datasource.write.precombine.field\": \"last_update_time\", \"hoodie.datasource.hive_sync.enable\": \"true\", \"hoodie.datasource.hive_sync.table\": \"my_hudi_table\", \"hoodie.datasource.hive_sync.partition_fields\": \"creation_date\", \"hoodie.datasource.hive_sync.partition_extractor_class\": \"org.apache.hudi.hive.MultiPartKeysValueExtractor\", \"hoodie.index.type\": \"GLOBAL_BLOOM\", # This is required if we want to ensure we upsert a record, even if the partition changes \"hoodie.bloom.index.update.partition.path\": \"true\", # This is required to write the data into the new partition (defaults to false in 0.8.0, true in 0.9.0) } # Write a DataFrame as a Hudi dataset inputDF.write.format(\"org.apache.hudi\").option( \"hoodie.datasource.write.operation\", \"insert\" ).options(**hudiOptions).mode(\"overwrite\").save(f\"s3://{S3_BUCKET_NAME}/tmp/hudi/\") When we look at the file structure on S3, we see a few things:\n A hoodie.properties file  2022-01-14 00:33:46 503 tmp/hudi/.hoodie/hoodie.properties This file contains certain metadata about the Hudi dataset:\n#Properties saved on Fri Jan 14 00:33:45 UTC 2022 #Fri Jan 14 00:33:45 UTC 2022 hoodie.table.precombine.field=last_update_time hoodie.table.partition.fields=creation_date hoodie.table.type=COPY_ON_WRITE hoodie.archivelog.folder=archived hoodie.populate.meta.fields=true hoodie.timeline.layout.version=1 hoodie.table.version=2 hoodie.table.recordkey.fields=id hoodie.table.base.file.format=PARQUET hoodie.table.keygenerator.class=org.apache.hudi.keygen.SimpleKeyGenerator hoodie.table.name=my_hudi_table A set of commit-related files  2022-01-14 00:33:57 2706 tmp/hudi/.hoodie/20220114003341.commit 2022-01-14 00:33:48 0 tmp/hudi/.hoodie/20220114003341.commit.requested 2022-01-14 00:33:52 1842 tmp/hudi/.hoodie/20220114003341.inflight The actual .parquet data files and associated metadata organized into date-based partitions.  2022-01-14 00:33:54 93 tmp/hudi/2015-01-01/.hoodie_partition_metadata 2022-01-14 00:33:54 434974 tmp/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet 2022-01-14 00:33:55 93 tmp/hudi/2015-01-02/.hoodie_partition_metadata 2022-01-14 00:33:55 434943 tmp/hudi/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet We then update the creation_date of one row in this dataset.\nfrom pyspark.sql.functions import lit # Create a new DataFrame from the first row of inputDF with a different creation_date value updateDF = inputDF.where(\"id = 100\").withColumn(\"creation_date\", lit(\"2022-01-11\")) updateDF.show() # Update by using the \"upsert\" operation updateDF.write.format(\"org.apache.hudi\").option( \"hoodie.datasource.write.operation\", \"upsert\" ).options(**hudiOptions).mode(\"append\").save(f\"s3://{S3_BUCKET_NAME}/tmp/hudi/\") One thing to note here is that since we’re updating a partition value (DANGER!), we had to set the hoodie.index.type to GLOBAL_BLOOM as well as setting hoodie.bloom.index.update.partition.path to true. This can have a large impact on performance so normally we would try not to change a partition value in a production environment, but it’s useful here to see the impact it has. You can mind more details in the Hudi FAQ about Hudi indexing.\nAfter this write, we have a new set of commit-related files on S3:\n2022-01-14 00:34:15 2706 tmp/hudi/.hoodie/20220114003401.commit 2022-01-14 00:34:03 0 tmp/hudi/.hoodie/20220114003401.commit.requested 2022-01-14 00:34:08 2560 tmp/hudi/.hoodie/20220114003401.inflight And we actually have 2 new .parquet files:\n2022-01-14 00:34:12 434925 tmp/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet ... 2022-01-14 00:34:13 93 tmp/hudi/2022-01-11/.hoodie_partition_metadata 2022-01-14 00:34:14 434979 tmp/hudi/2022-01-11/0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet So what happened with the update is that the old partition (2015-01-01) had its data overwritten and the new partition (2022-01-11) also had data written to it. You can now see why the global bloom index could have such a large impact on write performance as there is significant potential for write amplication.\nIf we query the data and add the source filename for each row, we can also see that data for the old partition now comes from the new parquet file (notice the commit ID 20220114003401 shows up in the filename):\nfrom pyspark.sql.functions import input_file_name snapshotQueryDF = spark.read \\ .format('org.apache.hudi') \\ .load(f\"s3://{S3_BUCKET_NAME}/tmp/hudi/\") \\ .select('id', 'creation_date') \\ .withColumn(\"filename\", input_file_name()) snapshotQueryDF.show(truncate=False) +---+-------------+------------------------------------------------------------------------------------------------------------------------------+ |id |creation_date|filename | +---+-------------+------------------------------------------------------------------------------------------------------------------------------+ |100|2022-01-11 |/hudi/2022-01-11/0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet | |105|2015-01-02 |/hudi/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet | |104|2015-01-02 |/hudi/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet | |102|2015-01-01 |/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet | |103|2015-01-01 |/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet | |101|2015-01-01 |/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet | +---+-------------+------------------------------------------------------------------------------------------------------------------------------+ One other thing to note is that Hudi adds quite a bit of metadata to your Parquet files. If we use native Spark to read one of the Parquet files and show it, we see that there’s various _hoodie-prefixed keys.\nfrom pyspark.sql.functions import split rawDF = ( spark.read.parquet(f\"s3://{S3_BUCKET_NAME}/tmp/hudi/*/*.parquet\") .withColumn(\"filename\", split(input_file_name(), \"tmp/hudi\").getItem(1)) .sort(\"_hoodie_commit_time\", \"_hoodie_commit_seqno\") ) rawDF.show(truncate=False) +-------------------+--------------------+------------------+----------------------+------------------------------------------------------------------------+---+-------------+---------------------------+------------------------------------------------------------------------------------+ |_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|_hoodie_file_name |id |creation_date|last_update_time |filename | +-------------------+--------------------+------------------+----------------------+------------------------------------------------------------------------+---+-------------+---------------------------+------------------------------------------------------------------------------------+ |20220114003341 |20220114003341_0_1 |100 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |100|2015-01-01 |2015-01-01T13:51:39.340396Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet | |20220114003341 |20220114003341_0_2 |102 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |102|2015-01-01 |2015-01-01T13:51:40.417052Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet| |20220114003341 |20220114003341_0_2 |102 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |102|2015-01-01 |2015-01-01T13:51:40.417052Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet | |20220114003341 |20220114003341_0_3 |103 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |103|2015-01-01 |2015-01-01T13:51:40.519832Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet| |20220114003341 |20220114003341_0_3 |103 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |103|2015-01-01 |2015-01-01T13:51:40.519832Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet | |20220114003341 |20220114003341_0_4 |101 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |101|2015-01-01 |2015-01-01T12:14:58.597216Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet| |20220114003341 |20220114003341_0_4 |101 |2015-01-01 |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet |101|2015-01-01 |2015-01-01T12:14:58.597216Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet | |20220114003341 |20220114003341_1_5 |105 |2015-01-02 |43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet |105|2015-01-02 |2015-01-01T13:51:42.248818Z|/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet | |20220114003341 |20220114003341_1_6 |104 |2015-01-02 |43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet |104|2015-01-02 |2015-01-01T12:15:00.512679Z|/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet | |20220114003401 |20220114003401_1_1 |100 |2022-01-11 |0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet|100|2022-01-11 |2015-01-01T13:51:39.340396Z|/2022-01-11/0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet| +-------------------+--------------------+------------------+----------------------+------------------------------------------------------------------------+---+-------------+---------------------------+------------------------------------------------------------------------------------+ In the background, Hudi figures out which commits and values to show based on the commit files and metadata in the parquet files.\nApache Iceberg  📹 Intro to Apache Iceberg video\n When I first heard about Iceberg, the phrase “table format for storing large, slow-moving tabular data” didn’t really make sense to me. But after working with data lakes at scale, it became quite clear. Apache Hive is a popular data warehouse project that provides a SQL-like interface to large datasets. Built on top of Hadoop, it originally used HDFS as its data store. With cloud migrations, object stores like Amazon S3 enabled the ability to store even more data particularly without the operational concerns of a large Hadoop cluster, but with some limitations when compared to HDFS. Specifically, directory listings are slower (simple physics here, network calls are slower), renames are not atomic (by design), and results were previously eventually consistent.\nSo imagine you are Netflix, you have hundreds of petabytes of data stored on S3, and you need a way for your organization to efficiently query this. You need a data storage layer that reduces or removes directory listings, you want atomic changes, and you want to ensure that when you’re reading your data you get consistent results. There is more to Iceberg, but I’m simplifying because this helped me understand. :)\nThese were some of the original goals for Iceberg, so let’s dive in and see how it works. Similar to Hudi, we’ll create a simple Spark DataFrame and write that to S3 in Iceberg format.\nI should note that much of Iceberg is focused around Spark SQL, so I will switch to that below for certain operations.\n# Create a DataFrame inputDF = spark.createDataFrame( [ (\"100\", \"2015-01-01\", \"2015-01-01T13:51:39.340396Z\"), (\"101\", \"2015-01-01\", \"2015-01-01T12:14:58.597216Z\"), (\"102\", \"2015-01-01\", \"2015-01-01T13:51:40.417052Z\"), (\"103\", \"2015-01-01\", \"2015-01-01T13:51:40.519832Z\"), (\"104\", \"2015-01-02\", \"2015-01-01T12:15:00.512679Z\"), (\"105\", \"2015-01-02\", \"2015-01-01T13:51:42.248818Z\"), ], [\"id\", \"creation_date\", \"last_update_time\"], ) # Write a DataFrame as an Iceberg dataset inputDF.write.format(\"iceberg\").mode(\"overwrite\").partitionBy(\"creation_date\").option( \"path\", f\"s3://{S3_BUCKET_NAME}/tmp/iceberg/\" ).saveAsTable(ICEBERG_TABLE_NAME) There are two main differences here - there is not as much “configuration” as we had to do with Hudi and we also explicitly use saveAsTable. With Iceberg, much of the metadata is stored in a data catalog so creating the table is necessary. Let’s see what happened on S3.\n First, we have a metadata.json file  2022-01-28 06:03:50 2457 tmp/iceberg/metadata/00000-bb1d38a9-af77-42c4-a7b7-69416fe36d9c.metadata.json Then a snapshot manifest list file  2022-01-28 06:03:50 3785 tmp/iceberg/metadata/snap-7934053180928033536-1-e79c79ba-c7f0-45ad-8f2e-fd1bc349db55.avro And a manifest file  2022-01-28 06:03:50 6244 tmp/iceberg/metadata/e79c79ba-c7f0-45ad-8f2e-fd1bc349db55-m0.avro And finally, we’ve got our Parquet data files  2022-01-28 06:03:49 1197 tmp/iceberg/data/creation_date=2015-01-01/00000-4-fa9a18fd-abc4-4e04-91b4-e2ac4c9531be-00001.parquet 2022-01-28 06:03:49 1171 tmp/iceberg/data/creation_date=2015-01-01/00001-5-eab30115-a1d6-4918-abb4-a198ac12b262-00001.parquet 2022-01-28 06:03:50 1182 tmp/iceberg/data/creation_date=2015-01-02/00001-5-eab30115-a1d6-4918-abb4-a198ac12b262-00002.parquet There are a lot of moving pieces here, but the image from the Iceberg spec illustrates it quite well.\nSimilar to Hudi, our data is written to Parquet files in each partition, although Hive-style partitioning is used by default. Hudi can also do this by setting the hoodie.datasource.write.hive_style_partitioning parameter.\nDifferent from Hudi, though, is the usage of the data catalog to identify the current metadata file to use. That metadata file contains references to a list of manifest files to use to determine which data files compose the dataset for that particular version, also known as snapshots. The snapshot data also has quite a bit of additional informaiton. Let’s update our dataset then take a look at S3 again and the snapshot portion of the metadata file.\nspark.sql(f\"UPDATE {ICEBERG_TABLE_NAME} SET creation_date = '2022-01-11' WHERE id = 100\") We can see that we have:\n 2 new .parquet data files  2022-01-28 06:07:07 1180 tmp/iceberg/data/creation_date=2015-01-01/00000-16-033354bd-7b02-44f4-95e2-7045e10706fc-00001.parquet 2022-01-28 06:07:08 1171 tmp/iceberg/data/creation_date=2022-01-11/00000-16-033354bd-7b02-44f4-95e2-7045e10706fc-00002.parquet As well as:\n 1 new metadata.json file 2 new .avro metadata listings 1 new snap-*.avro snapshot file  Let’s look at the snapshot portion of the metadata.json file.\n\"snapshots\": [ { \"manifest-list\": \"s3:///tmp/iceberg/metadata/snap-7934053180928033536-1-e79c79ba-c7f0-45ad-8f2e-fd1bc349db55.avro\", \"schema-id\": 0, \"snapshot-id\": 7934053180928033536, \"summary\": { \"added-data-files\": \"3\", \"added-files-size\": \"3550\", \"added-records\": \"6\", \"changed-partition-count\": \"2\", \"operation\": \"append\", \"spark.app.id\": \"application_1643153254969_0029\", \"total-data-files\": \"3\", \"total-delete-files\": \"0\", \"total-equality-deletes\": \"0\", \"total-files-size\": \"3550\", \"total-position-deletes\": \"0\", \"total-records\": \"6\" }, \"timestamp-ms\": 1643349829278 }, { \"manifest-list\": \"s3:///tmp/iceberg/metadata/snap-5441092870212826638-1-605de48f-8ccf-450c-935e-bbd4194ee8cc.avro\", \"parent-snapshot-id\": 7934053180928033536, \"schema-id\": 0, \"snapshot-id\": 5441092870212826638, \"summary\": { \"added-data-files\": \"2\", \"added-files-size\": \"2351\", \"added-records\": \"3\", \"changed-partition-count\": \"2\", \"deleted-data-files\": \"1\", \"deleted-records\": \"3\", \"operation\": \"overwrite\", \"removed-files-size\": \"1197\", \"spark.app.id\": \"application_1643153254969_0029\", \"total-data-files\": \"4\", \"total-delete-files\": \"0\", \"total-equality-deletes\": \"0\", \"total-files-size\": \"4704\", \"total-position-deletes\": \"0\", \"total-records\": \"6\" }, \"timestamp-ms\": 1643350027635 } ] This is pretty amazing - we see how many files and records were added or deleted, what the file sizes were, and even what the Spark app_id was! 🤯 Some of this data is in the manifest-list files as well, but you can begin to see just how much you could potentially optimize your queries using this data.\nDelta Lake  📹 Intro to Delta Lake video\n Delta Lake was also introduced by Databricks as a way to address many of the challenges of Data Lakes. Similar to Hudi and Iceberg its goals include unifying batch and stream processing, ACID transactions, and scalable metadata handling among others.\nAgain, we’ll create a simple Spark DataFrame and write it to S3 in Delta format.\n# Create a DataFrame inputDF = spark.createDataFrame( [ (\"100\", \"2015-01-01\", \"2015-01-01T13:51:39.340396Z\"), (\"101\", \"2015-01-01\", \"2015-01-01T12:14:58.597216Z\"), (\"102\", \"2015-01-01\", \"2015-01-01T13:51:40.417052Z\"), (\"103\", \"2015-01-01\", \"2015-01-01T13:51:40.519832Z\"), (\"104\", \"2015-01-02\", \"2015-01-01T12:15:00.512679Z\"), (\"105\", \"2015-01-02\", \"2015-01-01T13:51:42.248818Z\"), ], [\"id\", \"creation_date\", \"last_update_time\"], ) # Write a DataFrame as a Delta dataset inputDF.write.format(\"delta\").mode(\"overwrite\").option( \"overwriteSchema\", \"true\" ).partitionBy(\"creation_date\").save(f\"s3://{S3_BUCKET_NAME}/tmp/delta/\") On S3, we now see the following files:\n a 00000000000000000000.json file  2022-01-24 22:57:54 2120 tmp/delta/_delta_log/00000000000000000000.json Several .snappy.parquet files  2022-01-24 22:57:52 875 tmp/delta/creation_date=2015-01-01/part-00005-2e09dbe4-469e-40dc-9b36-833480f6d375.c000.snappy.parquet 2022-01-24 22:57:52 875 tmp/delta/creation_date=2015-01-01/part-00010-848c69e1-71fb-4f8f-a19a-dd74e0ef1b8a.c000.snappy.parquet 2022-01-24 22:57:53 875 tmp/delta/creation_date=2015-01-01/part-00015-937d1837-0f03-4306-9b4e-4366207e688d.c000.snappy.parquet 2022-01-24 22:57:54 875 tmp/delta/creation_date=2015-01-01/part-00021-978a808e-4c36-4646-b7b1-ef5a21e706d8.c000.snappy.parquet 2022-01-24 22:57:54 875 tmp/delta/creation_date=2015-01-02/part-00026-538e1ac6-055e-4e72-9177-63daaaae1f98.c000.snappy.parquet 2022-01-24 22:57:52 875 tmp/delta/creation_date=2015-01-02/part-00031-8a03451a-0297-4c43-b64d-56db25807d02.c000.snappy.parquet OK, so what’s in that _delta_log file? Similar to Iceberg, quite a bit of information about this initial write to S3 including the number of files written, the schema of the dataset, and even the individual add operations for each file.\n{ \"commitInfo\": { \"timestamp\": 1643065073634, \"operation\": \"WRITE\", \"operationParameters\": { \"mode\": \"Overwrite\", \"partitionBy\": \"[\\\"creation_date\\\"]\" }, \"isBlindAppend\": false, \"operationMetrics\": { \"numFiles\": \"6\", \"numOutputBytes\": \"5250\", \"numOutputRows\": \"6\" } } } { \"protocol\": { \"minReaderVersion\": 1, \"minWriterVersion\": 2 } } { \"metaData\": { \"id\": \"a7f4b1d1-09f6-4475-894a-0eec90d1aab5\", \"format\": { \"provider\": \"parquet\", \"options\": {} }, \"schemaString\": \"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"creation_date\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"last_update_time\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}}]}\", \"partitionColumns\": [ \"creation_date\" ], \"configuration\": {}, \"createdTime\": 1643065064066 } } { \"add\": { \"path\": \"creation_date=2015-01-01/part-00005-2e09dbe4-469e-40dc-9b36-833480f6d375.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2015-01-01\" }, \"size\": 875, \"modificationTime\": 1643065072000, \"dataChange\": true } } { \"add\": { \"path\": \"creation_date=2015-01-01/part-00010-848c69e1-71fb-4f8f-a19a-dd74e0ef1b8a.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2015-01-01\" }, \"size\": 875, \"modificationTime\": 1643065072000, \"dataChange\": true } } { \"add\": { \"path\": \"creation_date=2015-01-01/part-00015-937d1837-0f03-4306-9b4e-4366207e688d.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2015-01-01\" }, \"size\": 875, \"modificationTime\": 1643065073000, \"dataChange\": true } } { \"add\": { \"path\": \"creation_date=2015-01-01/part-00021-978a808e-4c36-4646-b7b1-ef5a21e706d8.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2015-01-01\" }, \"size\": 875, \"modificationTime\": 1643065074000, \"dataChange\": true } } { \"add\": { \"path\": \"creation_date=2015-01-02/part-00026-538e1ac6-055e-4e72-9177-63daaaae1f98.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2015-01-02\" }, \"size\": 875, \"modificationTime\": 1643065074000, \"dataChange\": true } } { \"add\": { \"path\": \"creation_date=2015-01-02/part-00031-8a03451a-0297-4c43-b64d-56db25807d02.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2015-01-02\" }, \"size\": 875, \"modificationTime\": 1643065072000, \"dataChange\": true } } Alright, let’s go ahead and update one of our rows. Delta Lake provides a merge operation that we can use. We’ll use the syntax from the docs that’s slightly different from native Spark as it creates a DeltaTable object.\nfrom pyspark.sql.functions import lit # Create a new DataFrame from the first row of inputDF with a different creation_date value updateDF = inputDF.where(\"id = 100\").withColumn(\"creation_date\", lit(\"2022-01-11\")) from delta.tables import * from pyspark.sql.functions import * deltaTable = DeltaTable.forPath(spark, f\"s3://{S3_BUCKET_NAME}/tmp/delta/\") deltaTable.alias(\"oldData\") \\ .merge( updateDF.alias(\"newData\"), \"oldData.id = newData.id\") \\ .whenMatchedUpdate(set = { \"creation_date\": col(\"newData.creation_date\") }) \\ .execute() Interestingly, now when we look at S3 we see 1 new json file and only 1 new parquet file (Remember Hudi and Iceberg both had 2 new parquet files).\n2022-01-24 23:05:46 1018 tmp/delta/_delta_log/00000000000000000001.json 2022-01-24 23:05:46 875 tmp/delta/creation_date=2022-01-11/part-00000-3f3fd83a-b876-4b6f-8f64-d8a4189392ae.c000.snappy.parquet If we look at that new JSON file we see something really interesting:\n{ \"commitInfo\": { \"timestamp\": 1643065545396, \"operation\": \"MERGE\", \"operationParameters\": { \"predicate\": \"(oldData.`id` = newData.`id`)\", \"matchedPredicates\": \"[{\\\"actionType\\\":\\\"update\\\"}]\", \"notMatchedPredicates\": \"[]\" }, \"readVersion\": 0, \"isBlindAppend\": false, \"operationMetrics\": { \"numTargetRowsCopied\": \"0\", \"numTargetRowsDeleted\": \"0\", \"numTargetFilesAdded\": \"1\", \"executionTimeMs\": \"4705\", \"numTargetRowsInserted\": \"0\", \"scanTimeMs\": \"3399\", \"numTargetRowsUpdated\": \"1\", \"numOutputRows\": \"1\", \"numSourceRows\": \"1\", \"numTargetFilesRemoved\": \"1\", \"rewriteTimeMs\": \"1265\" } } } { \"remove\": { \"path\": \"creation_date=2015-01-01/part-00005-2e09dbe4-469e-40dc-9b36-833480f6d375.c000.snappy.parquet\", \"deletionTimestamp\": 1643065545378, \"dataChange\": true, \"extendedFileMetadata\": true, \"partitionValues\": { \"creation_date\": \"2015-01-01\" }, \"size\": 875 } } { \"add\": { \"path\": \"creation_date=2022-01-11/part-00000-3f3fd83a-b876-4b6f-8f64-d8a4189392ae.c000.snappy.parquet\", \"partitionValues\": { \"creation_date\": \"2022-01-11\" }, \"size\": 875, \"modificationTime\": 1643065546000, \"dataChange\": true } } In addition to the operationMetrics that gives us insight into how the data changed on “disk”, we also now see both a remove and add operation. In Delta Lake (and I’m not quite sure why this happened yet…), each row was written to an individual .parquet file! So for this second version of the data, the fact that that row was updated simply lives in the metadata because it was the only row stored in that Parquet file. I’m guessing this is simply because my dataset is so small the default number of partitions in Spark/Delta Lake resulted in this write configuration.\nSnapshots So now we’ve got a good idea of the semantics of each of these storage layers. Let’s take one more look at an important component of all of them and that’s snapshots!\nHudi Hudi has a concept of “point-in-time” queries where you provide it a range of two commit timestamps and it will show you what the data looked like at that point in time.\n# Query data from the first version of the table readOptions = { 'hoodie.datasource.query.type': 'incremental', 'hoodie.datasource.read.begin.instanttime': '0', 'hoodie.datasource.read.end.instanttime': '20220114003341', } incQueryDF = spark.read \\ .format('org.apache.hudi') \\ .options(**readOptions) \\ .load(f\"s3://{S3_BUCKET_NAME}/tmp/hudi\") incQueryDF.show() Iceberg Iceberg supports a similar mechanism called time travel and you can use either a snapshot-id or as-of-timestamp similar to Hudi.\n# time travel to 2022-01-27 22:04:00 -0800 df = spark.read \\ .option(\"as-of-timestamp\", \"1643349840000\") \\ .format(\"iceberg\") \\ .load(ICEBERG_TABLE_NAME) df.show() Delta Lake And, of course, Delta Lake supports this as well using either Spark SQL or DataFrames. And similar to Iceberg you can use versionAsOf or timestampAsOf.\n# time travel to 2022-01-24 23:00 df1 = ( spark.read.format(\"delta\") .option(\"timestampAsOf\", \"2022-01-24 23:00\") .load(f\"s3://{S3_BUCKET_NAME}/tmp/delta/\") ) Deletes I bet you’re surprised I haven’t mentioned deletes or GDPR yet. Don’t worry…I will. 😀 But first I just wanted to understand exactly how these different systems work.\nWrapup In this post, we reviewed the basics of Apache Hudi, Apache Iceberg, and Delta Lake - modern data lake storage layers. All these frameworks enable a set of functionality that optimize working with data in cloud-based object stores, albeit with slightly different approaches.\n","wordCount":"2607","inLanguage":"en","image":"https://dacort.dev/posts/modern-data-lake-storage-layers/lake.jpg","datePublished":"2022-02-02T14:22:22-08:00","dateModified":"2022-02-02T14:22:22-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://dacort.dev/posts/modern-data-lake-storage-layers/"},"publisher":{"@type":"Organization","name":"Damon Cortesi","logo":{"@type":"ImageObject","url":"https://dacort.dev/images/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://dacort.dev/ accesskey=h title="Damon Cortesi (Alt + H)">Damon Cortesi</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://dacort.dev/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://dacort.dev/posts/ title=Blog><span>Blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dacort.dev/>Home</a>&nbsp;»&nbsp;<a href=https://dacort.dev/posts/>Posts</a></div><h1 class=post-title>An Introduction to Modern Data Lake Storage Layers</h1><div class=post-meta>February 2, 2022&nbsp;·&nbsp;13 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#apache-hudi aria-label="Apache Hudi">Apache Hudi</a></li><li><a href=#apache-iceberg aria-label="Apache Iceberg">Apache Iceberg</a></li><li><a href=#delta-lake aria-label="Delta Lake">Delta Lake</a></li><li><a href=#snapshots aria-label=Snapshots>Snapshots</a><ul><li><a href=#hudi aria-label=Hudi>Hudi</a></li><li><a href=#iceberg aria-label=Iceberg>Iceberg</a></li><li><a href=#delta-lake-1 aria-label="Delta Lake">Delta Lake</a></li></ul></li><li><a href=#deletes aria-label=Deletes>Deletes</a></li><li><a href=#wrapup aria-label=Wrapup>Wrapup</a></li></ul></div></details></div><div class=post-content><p>In recent years we&rsquo;ve seen a rise in new storage layers for data lakes. In 2017, <a href=https://eng.uber.com/hoodie/>Uber announced Hudi</a> - an incremental processing framework for data pipelines. In 2018, <a href=https://conferences.oreilly.com/strata/strata-ny-2018/public/schedule/detail/69503.html>Netflix introduced Iceberg</a> - a new table format for managing extremely large cloud datasets. And in 2019, <a href=https://techcrunch.com/2019/04/24/databricks-open-sources-delta-lake-to-make-data-lakes-more-reliable/>Databricks open-sourced Delta Lake</a> - originally intended to bring ACID transactions to data lakes.</p><blockquote><p>📹 <em>If you&rsquo;d like to watch a video that discusses the content of this post, I&rsquo;ve also recorded <a href="https://www.youtube.com/watch?v=fryfx0Zg7KA">an overview here</a>. Each relevant section below will also link to individual timestamps.</em></p></blockquote><p>This post aims to introduce each of these engines and give some insight into how they function under the hood and some of the differences in each. While I&rsquo;ll summarize the findings here, you can also view my Jupyter notebooks for each in my <a href=https://github.com/dacort/modern-data-lake-storage-layers/tree/main/notebooks>modern-data-lake-storage-layers</a> repository. We begin with basic operations of writing and updating datasets.</p><p>One thing to note about all of these frameworks is that each began with a different challenge they were solving for, but over time they have begun to converge on a common set of functionality.</p><h2 id=apache-hudi>Apache Hudi<a hidden class=anchor aria-hidden=true href=#apache-hudi>#</a></h2><blockquote><p>📹 <a href="https://www.youtube.com/watch?v=fryfx0Zg7KA&t=323s">Intro to Apache Hudi video</a></p></blockquote><p>Apache Hudi (Hadoop Upsert Delete and Incremental) was originally designed as an incremental stream processing framework and was built to combine the benefits of stream and batch processing. Hudi can be used with Spark, Flink, Presto, Trino and Hive, but much of the original work was focused around Spark and that&rsquo;s what I use for these examples.</p><p>For Hudi, we create a simple Spark DataFrame partitioned by <code>creation_date</code> and write that to S3.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Create a DataFrame</span>
inputDF <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>createDataFrame(
    [
        (<span style=color:#e6db74>&#34;100&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:39.340396Z&#34;</span>),
        (<span style=color:#e6db74>&#34;101&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T12:14:58.597216Z&#34;</span>),
        (<span style=color:#e6db74>&#34;102&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:40.417052Z&#34;</span>),
        (<span style=color:#e6db74>&#34;103&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:40.519832Z&#34;</span>),
        (<span style=color:#e6db74>&#34;104&#34;</span>, <span style=color:#e6db74>&#34;2015-01-02&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T12:15:00.512679Z&#34;</span>),
        (<span style=color:#e6db74>&#34;105&#34;</span>, <span style=color:#e6db74>&#34;2015-01-02&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:42.248818Z&#34;</span>),
    ],
    [<span style=color:#e6db74>&#34;id&#34;</span>, <span style=color:#e6db74>&#34;creation_date&#34;</span>, <span style=color:#e6db74>&#34;last_update_time&#34;</span>],
)

<span style=color:#75715e># Specify common DataSourceWriteOptions in the single hudiOptions variable</span>
hudiOptions <span style=color:#f92672>=</span> {
    <span style=color:#e6db74>&#34;hoodie.table.name&#34;</span>: <span style=color:#e6db74>&#34;my_hudi_table&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.write.recordkey.field&#34;</span>: <span style=color:#e6db74>&#34;id&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.write.partitionpath.field&#34;</span>: <span style=color:#e6db74>&#34;creation_date&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.write.precombine.field&#34;</span>: <span style=color:#e6db74>&#34;last_update_time&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.hive_sync.enable&#34;</span>: <span style=color:#e6db74>&#34;true&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.hive_sync.table&#34;</span>: <span style=color:#e6db74>&#34;my_hudi_table&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.hive_sync.partition_fields&#34;</span>: <span style=color:#e6db74>&#34;creation_date&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.datasource.hive_sync.partition_extractor_class&#34;</span>: <span style=color:#e6db74>&#34;org.apache.hudi.hive.MultiPartKeysValueExtractor&#34;</span>,
    <span style=color:#e6db74>&#34;hoodie.index.type&#34;</span>: <span style=color:#e6db74>&#34;GLOBAL_BLOOM&#34;</span>,  <span style=color:#75715e># This is required if we want to ensure we upsert a record, even if the partition changes</span>
    <span style=color:#e6db74>&#34;hoodie.bloom.index.update.partition.path&#34;</span>: <span style=color:#e6db74>&#34;true&#34;</span>,  <span style=color:#75715e># This is required to write the data into the new partition (defaults to false in 0.8.0, true in 0.9.0)</span>
}

<span style=color:#75715e># Write a DataFrame as a Hudi dataset</span>
inputDF<span style=color:#f92672>.</span>write<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;org.apache.hudi&#34;</span>)<span style=color:#f92672>.</span>option(
    <span style=color:#e6db74>&#34;hoodie.datasource.write.operation&#34;</span>, <span style=color:#e6db74>&#34;insert&#34;</span>
)<span style=color:#f92672>.</span>options(<span style=color:#f92672>**</span>hudiOptions)<span style=color:#f92672>.</span>mode(<span style=color:#e6db74>&#34;overwrite&#34;</span>)<span style=color:#f92672>.</span>save(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/hudi/&#34;</span>)
</code></pre></div><p>When we look at the file structure on S3, we see a few things:</p><ol><li>A <code>hoodie.properties</code> file</li></ol><pre><code>2022-01-14 00:33:46        503 tmp/hudi/.hoodie/hoodie.properties
</code></pre><p>This file contains certain metadata about the Hudi dataset:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-ini data-lang=ini><span style=color:#75715e>#Properties saved on Fri Jan 14 00:33:45 UTC 2022</span>
<span style=color:#75715e>#Fri Jan 14 00:33:45 UTC 2022</span>
<span style=color:#a6e22e>hoodie.table.precombine.field</span><span style=color:#f92672>=</span><span style=color:#e6db74>last_update_time</span>
<span style=color:#a6e22e>hoodie.table.partition.fields</span><span style=color:#f92672>=</span><span style=color:#e6db74>creation_date</span>
<span style=color:#a6e22e>hoodie.table.type</span><span style=color:#f92672>=</span><span style=color:#e6db74>COPY_ON_WRITE</span>
<span style=color:#a6e22e>hoodie.archivelog.folder</span><span style=color:#f92672>=</span><span style=color:#e6db74>archived</span>
<span style=color:#a6e22e>hoodie.populate.meta.fields</span><span style=color:#f92672>=</span><span style=color:#e6db74>true</span>
<span style=color:#a6e22e>hoodie.timeline.layout.version</span><span style=color:#f92672>=</span><span style=color:#e6db74>1</span>
<span style=color:#a6e22e>hoodie.table.version</span><span style=color:#f92672>=</span><span style=color:#e6db74>2</span>
<span style=color:#a6e22e>hoodie.table.recordkey.fields</span><span style=color:#f92672>=</span><span style=color:#e6db74>id</span>
<span style=color:#a6e22e>hoodie.table.base.file.format</span><span style=color:#f92672>=</span><span style=color:#e6db74>PARQUET</span>
<span style=color:#a6e22e>hoodie.table.keygenerator.class</span><span style=color:#f92672>=</span><span style=color:#e6db74>org.apache.hudi.keygen.SimpleKeyGenerator</span>
<span style=color:#a6e22e>hoodie.table.name</span><span style=color:#f92672>=</span><span style=color:#e6db74>my_hudi_table</span>
</code></pre></div><ol start=2><li>A set of commit-related files</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-14 00:33:57       2706 tmp/hudi/.hoodie/20220114003341.commit
2022-01-14 00:33:48          0 tmp/hudi/.hoodie/20220114003341.commit.requested
2022-01-14 00:33:52       1842 tmp/hudi/.hoodie/20220114003341.inflight
</code></pre></div><ol start=3><li>The actual <code>.parquet</code> data files and associated metadata organized into date-based partitions.</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-14 00:33:54         93 tmp/hudi/2015-01-01/.hoodie_partition_metadata
2022-01-14 00:33:54     434974 tmp/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet
2022-01-14 00:33:55         93 tmp/hudi/2015-01-02/.hoodie_partition_metadata
2022-01-14 00:33:55     434943 tmp/hudi/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet
</code></pre></div><p>We then update the <code>creation_date</code> of one row in this dataset.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> pyspark.sql.functions <span style=color:#f92672>import</span> lit

<span style=color:#75715e># Create a new DataFrame from the first row of inputDF with a different creation_date value</span>
updateDF <span style=color:#f92672>=</span> inputDF<span style=color:#f92672>.</span>where(<span style=color:#e6db74>&#34;id = 100&#34;</span>)<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;creation_date&#34;</span>, lit(<span style=color:#e6db74>&#34;2022-01-11&#34;</span>))

updateDF<span style=color:#f92672>.</span>show()

<span style=color:#75715e># Update by using the &#34;upsert&#34; operation</span>
updateDF<span style=color:#f92672>.</span>write<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;org.apache.hudi&#34;</span>)<span style=color:#f92672>.</span>option(
    <span style=color:#e6db74>&#34;hoodie.datasource.write.operation&#34;</span>, <span style=color:#e6db74>&#34;upsert&#34;</span>
)<span style=color:#f92672>.</span>options(<span style=color:#f92672>**</span>hudiOptions)<span style=color:#f92672>.</span>mode(<span style=color:#e6db74>&#34;append&#34;</span>)<span style=color:#f92672>.</span>save(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/hudi/&#34;</span>)
</code></pre></div><p>One thing to note here is that since we&rsquo;re updating a partition value (<strong>DANGER!</strong>), we had to set the <code>hoodie.index.type</code> to <code>GLOBAL_BLOOM</code> as well as setting <code>hoodie.bloom.index.update.partition.path</code> to <code>true</code>. This can have a large impact on performance so normally we would try not to change a partition value in a production environment, but it&rsquo;s useful here to see the impact it has. You can mind more details in the Hudi FAQ about <a href=https://hudi.apache.org/learn/faq/#how-does-the-hudi-indexing-work--what-are-its-benefits>Hudi indexing</a>.</p><p>After this write, we have a new set of commit-related files on S3:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-14 00:34:15       2706 tmp/hudi/.hoodie/20220114003401.commit
2022-01-14 00:34:03          0 tmp/hudi/.hoodie/20220114003401.commit.requested
2022-01-14 00:34:08       2560 tmp/hudi/.hoodie/20220114003401.inflight
</code></pre></div><p>And we actually have <strong>2</strong> new <code>.parquet</code> files:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-14 00:34:12     434925 tmp/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet
...
2022-01-14 00:34:13         93 tmp/hudi/2022-01-11/.hoodie_partition_metadata
2022-01-14 00:34:14     434979 tmp/hudi/2022-01-11/0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet
</code></pre></div><p>So what happened with the update is that the old partition (<code>2015-01-01</code>) had its data overwritten and the new partition (<code>2022-01-11</code>) <em>also</em> had data written to it. You can now see why the global bloom index could have such a large impact on write performance as there is significant potential for write amplication.</p><p>If we query the data and add the source filename for each row, we can also see that data for the old partition now comes from the new parquet file (notice the commit ID <code>20220114003401</code> shows up in the filename):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span>  pyspark.sql.functions <span style=color:#f92672>import</span> input_file_name

snapshotQueryDF <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read \
    <span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#39;org.apache.hudi&#39;</span>) \
    <span style=color:#f92672>.</span>load(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/hudi/&#34;</span>) \
    <span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#39;id&#39;</span>, <span style=color:#e6db74>&#39;creation_date&#39;</span>) \
    <span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;filename&#34;</span>, input_file_name())
    
snapshotQueryDF<span style=color:#f92672>.</span>show(truncate<span style=color:#f92672>=</span>False)
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>+---+-------------+------------------------------------------------------------------------------------------------------------------------------+
|id |creation_date|filename                                                                                                                      |
+---+-------------+------------------------------------------------------------------------------------------------------------------------------+
|100|2022-01-11   |/hudi/2022-01-11/0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet                                     |
|105|2015-01-02   |/hudi/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet                                         |
|104|2015-01-02   |/hudi/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet                                         |
|102|2015-01-01   |/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet                                     |
|103|2015-01-01   |/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet                                     |
|101|2015-01-01   |/hudi/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet                                     |
+---+-------------+------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div><p>One other thing to note is that Hudi adds quite a bit of metadata to your Parquet files. If we use native Spark to read one of the Parquet files and show it, we see that there&rsquo;s various <code>_hoodie</code>-prefixed keys.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> pyspark.sql.functions <span style=color:#f92672>import</span> split

rawDF <span style=color:#f92672>=</span> (
    spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>parquet(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/hudi/*/*.parquet&#34;</span>)
    <span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;filename&#34;</span>, split(input_file_name(), <span style=color:#e6db74>&#34;tmp/hudi&#34;</span>)<span style=color:#f92672>.</span>getItem(<span style=color:#ae81ff>1</span>))
    <span style=color:#f92672>.</span>sort(<span style=color:#e6db74>&#34;_hoodie_commit_time&#34;</span>, <span style=color:#e6db74>&#34;_hoodie_commit_seqno&#34;</span>)
)
rawDF<span style=color:#f92672>.</span>show(truncate<span style=color:#f92672>=</span>False)
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>+-------------------+--------------------+------------------+----------------------+------------------------------------------------------------------------+---+-------------+---------------------------+------------------------------------------------------------------------------------+
|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|_hoodie_file_name                                                       |id |creation_date|last_update_time           |filename                                                                            |
+-------------------+--------------------+------------------+----------------------+------------------------------------------------------------------------+---+-------------+---------------------------+------------------------------------------------------------------------------------+
|20220114003341     |20220114003341_0_1  |100               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |100|2015-01-01   |2015-01-01T13:51:39.340396Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |
|20220114003341     |20220114003341_0_2  |102               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |102|2015-01-01   |2015-01-01T13:51:40.417052Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet|
|20220114003341     |20220114003341_0_2  |102               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |102|2015-01-01   |2015-01-01T13:51:40.417052Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |
|20220114003341     |20220114003341_0_3  |103               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |103|2015-01-01   |2015-01-01T13:51:40.519832Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet|
|20220114003341     |20220114003341_0_3  |103               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |103|2015-01-01   |2015-01-01T13:51:40.519832Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |
|20220114003341     |20220114003341_0_4  |101               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |101|2015-01-01   |2015-01-01T12:14:58.597216Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-37-13680_20220114003401.parquet|
|20220114003341     |20220114003341_0_4  |101               |2015-01-01            |57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |101|2015-01-01   |2015-01-01T12:14:58.597216Z|/2015-01-01/57f66198-5303-4922-9323-91737ec40d25-0_0-4-98_20220114003341.parquet    |
|20220114003341     |20220114003341_1_5  |105               |2015-01-02            |43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet    |105|2015-01-02   |2015-01-01T13:51:42.248818Z|/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet    |
|20220114003341     |20220114003341_1_6  |104               |2015-01-02            |43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet    |104|2015-01-02   |2015-01-01T12:15:00.512679Z|/2015-01-02/43051d12-87e7-4dfb-8201-6ce293cf0df7-0_1-6-99_20220114003341.parquet    |
|20220114003401     |20220114003401_1_1  |100               |2022-01-11            |0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet|100|2022-01-11   |2015-01-01T13:51:39.340396Z|/2022-01-11/0c210872-484e-428b-a9ca-90a26e42125c-0_1-43-13681_20220114003401.parquet|
+-------------------+--------------------+------------------+----------------------+------------------------------------------------------------------------+---+-------------+---------------------------+------------------------------------------------------------------------------------+
</code></pre></div><p>In the background, Hudi figures out which commits and values to show based on the commit files and metadata in the parquet files.</p><h2 id=apache-iceberg>Apache Iceberg<a hidden class=anchor aria-hidden=true href=#apache-iceberg>#</a></h2><blockquote><p>📹 <a href="https://www.youtube.com/watch?v=fryfx0Zg7KA&t=1039s">Intro to Apache Iceberg video</a></p></blockquote><p>When I first heard about Iceberg, the phrase &ldquo;table format for storing large, slow-moving tabular data&rdquo; didn&rsquo;t really make sense to me. But after working with data lakes at scale, it became quite clear. Apache Hive is a popular data warehouse project that provides a SQL-like interface to large datasets. Built on top of Hadoop, it originally used HDFS as its data store. With cloud migrations, object stores like Amazon S3 enabled the ability to store even more data particularly without the operational concerns of a large Hadoop cluster, but with some limitations when compared to HDFS. Specifically, directory listings are slower (simple physics here, network calls are slower), renames are not atomic (by design), and results were previously eventually consistent.</p><p>So imagine you are Netflix, you have <a href=https://netflixtechblog.com/optimizing-data-warehouse-storage-7b94a48fdcbe>hundreds of petabytes of data</a> stored on S3, and you need a way for your organization to efficiently query this. You need a data storage layer that reduces or removes directory listings, you want atomic changes, and you want to ensure that when you&rsquo;re reading your data you get consistent results. <em>There is more to Iceberg, but I&rsquo;m simplifying because this helped me understand. :)</em></p><p>These were some of the original goals for Iceberg, so let&rsquo;s dive in and see how it works. Similar to Hudi, we&rsquo;ll create a simple Spark DataFrame and write that to S3 in Iceberg format.</p><p>I should note that much of Iceberg is focused around Spark SQL, so I will switch to that below for certain operations.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Create a DataFrame</span>
inputDF <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>createDataFrame(
    [
        (<span style=color:#e6db74>&#34;100&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:39.340396Z&#34;</span>),
        (<span style=color:#e6db74>&#34;101&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T12:14:58.597216Z&#34;</span>),
        (<span style=color:#e6db74>&#34;102&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:40.417052Z&#34;</span>),
        (<span style=color:#e6db74>&#34;103&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:40.519832Z&#34;</span>),
        (<span style=color:#e6db74>&#34;104&#34;</span>, <span style=color:#e6db74>&#34;2015-01-02&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T12:15:00.512679Z&#34;</span>),
        (<span style=color:#e6db74>&#34;105&#34;</span>, <span style=color:#e6db74>&#34;2015-01-02&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:42.248818Z&#34;</span>),
    ],
    [<span style=color:#e6db74>&#34;id&#34;</span>, <span style=color:#e6db74>&#34;creation_date&#34;</span>, <span style=color:#e6db74>&#34;last_update_time&#34;</span>],
)

<span style=color:#75715e># Write a DataFrame as an Iceberg dataset</span>
inputDF<span style=color:#f92672>.</span>write<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;iceberg&#34;</span>)<span style=color:#f92672>.</span>mode(<span style=color:#e6db74>&#34;overwrite&#34;</span>)<span style=color:#f92672>.</span>partitionBy(<span style=color:#e6db74>&#34;creation_date&#34;</span>)<span style=color:#f92672>.</span>option(
    <span style=color:#e6db74>&#34;path&#34;</span>, f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/iceberg/&#34;</span>
)<span style=color:#f92672>.</span>saveAsTable(ICEBERG_TABLE_NAME)
</code></pre></div><p>There are two main differences here - there is not as much &ldquo;configuration&rdquo; as we had to do with Hudi and we also explicitly use <code>saveAsTable</code>. With Iceberg, much of the metadata is stored in a data catalog so creating the table is necessary. Let&rsquo;s see what happened on S3.</p><ol><li>First, we have a <code>metadata.json</code> file</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-28 06:03:50       2457 tmp/iceberg/metadata/00000-bb1d38a9-af77-42c4-a7b7-69416fe36d9c.metadata.json
</code></pre></div><ol start=2><li>Then a snapshot <strong>manifest list</strong> file</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-28 06:03:50       3785 tmp/iceberg/metadata/snap-7934053180928033536-1-e79c79ba-c7f0-45ad-8f2e-fd1bc349db55.avro
</code></pre></div><ol start=3><li>And a manifest file</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-28 06:03:50       6244 tmp/iceberg/metadata/e79c79ba-c7f0-45ad-8f2e-fd1bc349db55-m0.avro
</code></pre></div><ol start=4><li>And finally, we&rsquo;ve got our Parquet data files</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-28 06:03:49       1197 tmp/iceberg/data/creation_date=2015-01-01/00000-4-fa9a18fd-abc4-4e04-91b4-e2ac4c9531be-00001.parquet
2022-01-28 06:03:49       1171 tmp/iceberg/data/creation_date=2015-01-01/00001-5-eab30115-a1d6-4918-abb4-a198ac12b262-00001.parquet
2022-01-28 06:03:50       1182 tmp/iceberg/data/creation_date=2015-01-02/00001-5-eab30115-a1d6-4918-abb4-a198ac12b262-00002.parquet
</code></pre></div><p>There are a lot of moving pieces here, but the image from the Iceberg spec illustrates it quite well.</p><p><img loading=lazy src=iceberg-metadata.png alt="Iceberg Metadata Diagram"></p><p>Similar to Hudi, our data is written to Parquet files in each partition, although Hive-style partitioning is used by default. Hudi can also do this by setting the <a href=https://hudi.apache.org/docs/configurations/#hoodiedatasourcewritehive_style_partitioning><code>hoodie.datasource.write.hive_style_partitioning</code></a> parameter.</p><p>Different from Hudi, though, is the usage of the data catalog to identify the current metadata file to use. That metadata file contains references to a list of manifest files to use to determine which data files compose the dataset for that particular version, also known as snapshots. The snapshot data also has quite a bit of additional informaiton. Let&rsquo;s update our dataset then take a look at S3 again and the snapshot portion of the metadata file.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>spark<span style=color:#f92672>.</span>sql(f<span style=color:#e6db74>&#34;UPDATE {ICEBERG_TABLE_NAME} SET creation_date = &#39;2022-01-11&#39; WHERE id = 100&#34;</span>)
</code></pre></div><p>We can see that we have:</p><ul><li>2 new .parquet data files</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-28 06:07:07       1180 tmp/iceberg/data/creation_date=2015-01-01/00000-16-033354bd-7b02-44f4-95e2-7045e10706fc-00001.parquet
2022-01-28 06:07:08       1171 tmp/iceberg/data/creation_date=2022-01-11/00000-16-033354bd-7b02-44f4-95e2-7045e10706fc-00002.parquet
</code></pre></div><p>As well as:</p><ul><li>1 new metadata.json file</li><li>2 new .avro metadata listings</li><li>1 new snap-*.avro snapshot file</li></ul><p>Let&rsquo;s look at the snapshot portion of the <code>metadata.json</code> file.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=color:#e6db74>&#34;snapshots&#34;</span><span style=color:#960050;background-color:#1e0010>:</span> [
    {
        <span style=color:#f92672>&#34;manifest-list&#34;</span>: <span style=color:#e6db74>&#34;s3://&lt;BUCKET&gt;/tmp/iceberg/metadata/snap-7934053180928033536-1-e79c79ba-c7f0-45ad-8f2e-fd1bc349db55.avro&#34;</span>,
        <span style=color:#f92672>&#34;schema-id&#34;</span>: <span style=color:#ae81ff>0</span>,
        <span style=color:#f92672>&#34;snapshot-id&#34;</span>: <span style=color:#ae81ff>7934053180928033536</span>,
        <span style=color:#f92672>&#34;summary&#34;</span>: {
            <span style=color:#f92672>&#34;added-data-files&#34;</span>: <span style=color:#e6db74>&#34;3&#34;</span>,
            <span style=color:#f92672>&#34;added-files-size&#34;</span>: <span style=color:#e6db74>&#34;3550&#34;</span>,
            <span style=color:#f92672>&#34;added-records&#34;</span>: <span style=color:#e6db74>&#34;6&#34;</span>,
            <span style=color:#f92672>&#34;changed-partition-count&#34;</span>: <span style=color:#e6db74>&#34;2&#34;</span>,
            <span style=color:#f92672>&#34;operation&#34;</span>: <span style=color:#e6db74>&#34;append&#34;</span>,
            <span style=color:#f92672>&#34;spark.app.id&#34;</span>: <span style=color:#e6db74>&#34;application_1643153254969_0029&#34;</span>,
            <span style=color:#f92672>&#34;total-data-files&#34;</span>: <span style=color:#e6db74>&#34;3&#34;</span>,
            <span style=color:#f92672>&#34;total-delete-files&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
            <span style=color:#f92672>&#34;total-equality-deletes&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
            <span style=color:#f92672>&#34;total-files-size&#34;</span>: <span style=color:#e6db74>&#34;3550&#34;</span>,
            <span style=color:#f92672>&#34;total-position-deletes&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
            <span style=color:#f92672>&#34;total-records&#34;</span>: <span style=color:#e6db74>&#34;6&#34;</span>
        },
        <span style=color:#f92672>&#34;timestamp-ms&#34;</span>: <span style=color:#ae81ff>1643349829278</span>
    },
    {
        <span style=color:#f92672>&#34;manifest-list&#34;</span>: <span style=color:#e6db74>&#34;s3://&lt;BUCKET&gt;/tmp/iceberg/metadata/snap-5441092870212826638-1-605de48f-8ccf-450c-935e-bbd4194ee8cc.avro&#34;</span>,
        <span style=color:#f92672>&#34;parent-snapshot-id&#34;</span>: <span style=color:#ae81ff>7934053180928033536</span>,
        <span style=color:#f92672>&#34;schema-id&#34;</span>: <span style=color:#ae81ff>0</span>,
        <span style=color:#f92672>&#34;snapshot-id&#34;</span>: <span style=color:#ae81ff>5441092870212826638</span>,
        <span style=color:#f92672>&#34;summary&#34;</span>: {
            <span style=color:#f92672>&#34;added-data-files&#34;</span>: <span style=color:#e6db74>&#34;2&#34;</span>,
            <span style=color:#f92672>&#34;added-files-size&#34;</span>: <span style=color:#e6db74>&#34;2351&#34;</span>,
            <span style=color:#f92672>&#34;added-records&#34;</span>: <span style=color:#e6db74>&#34;3&#34;</span>,
            <span style=color:#f92672>&#34;changed-partition-count&#34;</span>: <span style=color:#e6db74>&#34;2&#34;</span>,
            <span style=color:#f92672>&#34;deleted-data-files&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
            <span style=color:#f92672>&#34;deleted-records&#34;</span>: <span style=color:#e6db74>&#34;3&#34;</span>,
            <span style=color:#f92672>&#34;operation&#34;</span>: <span style=color:#e6db74>&#34;overwrite&#34;</span>,
            <span style=color:#f92672>&#34;removed-files-size&#34;</span>: <span style=color:#e6db74>&#34;1197&#34;</span>,
            <span style=color:#f92672>&#34;spark.app.id&#34;</span>: <span style=color:#e6db74>&#34;application_1643153254969_0029&#34;</span>,
            <span style=color:#f92672>&#34;total-data-files&#34;</span>: <span style=color:#e6db74>&#34;4&#34;</span>,
            <span style=color:#f92672>&#34;total-delete-files&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
            <span style=color:#f92672>&#34;total-equality-deletes&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
            <span style=color:#f92672>&#34;total-files-size&#34;</span>: <span style=color:#e6db74>&#34;4704&#34;</span>,
            <span style=color:#f92672>&#34;total-position-deletes&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
            <span style=color:#f92672>&#34;total-records&#34;</span>: <span style=color:#e6db74>&#34;6&#34;</span>
        },
        <span style=color:#f92672>&#34;timestamp-ms&#34;</span>: <span style=color:#ae81ff>1643350027635</span>
    }
]
</code></pre></div><p>This is pretty amazing - we see how many files <strong>and records</strong> were added or deleted, what the file sizes were, and even what the Spark <code>app_id</code> was! 🤯 Some of this data is in the <code>manifest-list</code> files as well, but you can begin to see <em>just</em> how much you could potentially optimize your queries using this data.</p><h2 id=delta-lake>Delta Lake<a hidden class=anchor aria-hidden=true href=#delta-lake>#</a></h2><blockquote><p>📹 <a href="https://www.youtube.com/watch?v=fryfx0Zg7KA&t=1814s">Intro to Delta Lake video</a></p></blockquote><p>Delta Lake was also introduced by Databricks as a way to address many of the challenges of Data Lakes. Similar to Hudi and Iceberg its goals include unifying batch and stream processing, ACID transactions, and scalable metadata handling among others.</p><p>Again, we&rsquo;ll create a simple Spark DataFrame and write it to S3 in Delta format.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Create a DataFrame</span>
inputDF <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>createDataFrame(
    [
        (<span style=color:#e6db74>&#34;100&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:39.340396Z&#34;</span>),
        (<span style=color:#e6db74>&#34;101&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T12:14:58.597216Z&#34;</span>),
        (<span style=color:#e6db74>&#34;102&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:40.417052Z&#34;</span>),
        (<span style=color:#e6db74>&#34;103&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:40.519832Z&#34;</span>),
        (<span style=color:#e6db74>&#34;104&#34;</span>, <span style=color:#e6db74>&#34;2015-01-02&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T12:15:00.512679Z&#34;</span>),
        (<span style=color:#e6db74>&#34;105&#34;</span>, <span style=color:#e6db74>&#34;2015-01-02&#34;</span>, <span style=color:#e6db74>&#34;2015-01-01T13:51:42.248818Z&#34;</span>),
    ],
    [<span style=color:#e6db74>&#34;id&#34;</span>, <span style=color:#e6db74>&#34;creation_date&#34;</span>, <span style=color:#e6db74>&#34;last_update_time&#34;</span>],
)

<span style=color:#75715e># Write a DataFrame as a Delta dataset</span>
inputDF<span style=color:#f92672>.</span>write<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;delta&#34;</span>)<span style=color:#f92672>.</span>mode(<span style=color:#e6db74>&#34;overwrite&#34;</span>)<span style=color:#f92672>.</span>option(
    <span style=color:#e6db74>&#34;overwriteSchema&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>
)<span style=color:#f92672>.</span>partitionBy(<span style=color:#e6db74>&#34;creation_date&#34;</span>)<span style=color:#f92672>.</span>save(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/delta/&#34;</span>)
</code></pre></div><p>On S3, we now see the following files:</p><ol><li>a <code>00000000000000000000.json</code> file</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-24 22:57:54       2120 tmp/delta/_delta_log/00000000000000000000.json
</code></pre></div><ol start=2><li>Several <code>.snappy.parquet</code> files</li></ol><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-24 22:57:52        875 tmp/delta/creation_date=2015-01-01/part-00005-2e09dbe4-469e-40dc-9b36-833480f6d375.c000.snappy.parquet
2022-01-24 22:57:52        875 tmp/delta/creation_date=2015-01-01/part-00010-848c69e1-71fb-4f8f-a19a-dd74e0ef1b8a.c000.snappy.parquet
2022-01-24 22:57:53        875 tmp/delta/creation_date=2015-01-01/part-00015-937d1837-0f03-4306-9b4e-4366207e688d.c000.snappy.parquet
2022-01-24 22:57:54        875 tmp/delta/creation_date=2015-01-01/part-00021-978a808e-4c36-4646-b7b1-ef5a21e706d8.c000.snappy.parquet
2022-01-24 22:57:54        875 tmp/delta/creation_date=2015-01-02/part-00026-538e1ac6-055e-4e72-9177-63daaaae1f98.c000.snappy.parquet
2022-01-24 22:57:52        875 tmp/delta/creation_date=2015-01-02/part-00031-8a03451a-0297-4c43-b64d-56db25807d02.c000.snappy.parquet
</code></pre></div><p>OK, so what&rsquo;s in that <code>_delta_log</code> file? Similar to Iceberg, quite a bit of information about this initial write to S3 including the number of files written, the schema of the dataset, and even the individual <code>add</code> operations for each file.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>{
  <span style=color:#f92672>&#34;commitInfo&#34;</span>: {
    <span style=color:#f92672>&#34;timestamp&#34;</span>: <span style=color:#ae81ff>1643065073634</span>,
    <span style=color:#f92672>&#34;operation&#34;</span>: <span style=color:#e6db74>&#34;WRITE&#34;</span>,
    <span style=color:#f92672>&#34;operationParameters&#34;</span>: {
      <span style=color:#f92672>&#34;mode&#34;</span>: <span style=color:#e6db74>&#34;Overwrite&#34;</span>,
      <span style=color:#f92672>&#34;partitionBy&#34;</span>: <span style=color:#e6db74>&#34;[\&#34;creation_date\&#34;]&#34;</span>
    },
    <span style=color:#f92672>&#34;isBlindAppend&#34;</span>: <span style=color:#66d9ef>false</span>,
    <span style=color:#f92672>&#34;operationMetrics&#34;</span>: {
      <span style=color:#f92672>&#34;numFiles&#34;</span>: <span style=color:#e6db74>&#34;6&#34;</span>,
      <span style=color:#f92672>&#34;numOutputBytes&#34;</span>: <span style=color:#e6db74>&#34;5250&#34;</span>,
      <span style=color:#f92672>&#34;numOutputRows&#34;</span>: <span style=color:#e6db74>&#34;6&#34;</span>
    }
  }
}
{
  <span style=color:#f92672>&#34;protocol&#34;</span>: {
    <span style=color:#f92672>&#34;minReaderVersion&#34;</span>: <span style=color:#ae81ff>1</span>,
    <span style=color:#f92672>&#34;minWriterVersion&#34;</span>: <span style=color:#ae81ff>2</span>
  }
}
{
  <span style=color:#f92672>&#34;metaData&#34;</span>: {
    <span style=color:#f92672>&#34;id&#34;</span>: <span style=color:#e6db74>&#34;a7f4b1d1-09f6-4475-894a-0eec90d1aab5&#34;</span>,
    <span style=color:#f92672>&#34;format&#34;</span>: {
      <span style=color:#f92672>&#34;provider&#34;</span>: <span style=color:#e6db74>&#34;parquet&#34;</span>,
      <span style=color:#f92672>&#34;options&#34;</span>: {}
    },
    <span style=color:#f92672>&#34;schemaString&#34;</span>: <span style=color:#e6db74>&#34;{\&#34;type\&#34;:\&#34;struct\&#34;,\&#34;fields\&#34;:[{\&#34;name\&#34;:\&#34;id\&#34;,\&#34;type\&#34;:\&#34;string\&#34;,\&#34;nullable\&#34;:true,\&#34;metadata\&#34;:{}},{\&#34;name\&#34;:\&#34;creation_date\&#34;,\&#34;type\&#34;:\&#34;string\&#34;,\&#34;nullable\&#34;:true,\&#34;metadata\&#34;:{}},{\&#34;name\&#34;:\&#34;last_update_time\&#34;,\&#34;type\&#34;:\&#34;string\&#34;,\&#34;nullable\&#34;:true,\&#34;metadata\&#34;:{}}]}&#34;</span>,
    <span style=color:#f92672>&#34;partitionColumns&#34;</span>: [
      <span style=color:#e6db74>&#34;creation_date&#34;</span>
    ],
    <span style=color:#f92672>&#34;configuration&#34;</span>: {},
    <span style=color:#f92672>&#34;createdTime&#34;</span>: <span style=color:#ae81ff>1643065064066</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-01/part-00005-2e09dbe4-469e-40dc-9b36-833480f6d375.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-01&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065072000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-01/part-00010-848c69e1-71fb-4f8f-a19a-dd74e0ef1b8a.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-01&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065072000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-01/part-00015-937d1837-0f03-4306-9b4e-4366207e688d.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-01&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065073000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-01/part-00021-978a808e-4c36-4646-b7b1-ef5a21e706d8.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-01&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065074000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-02/part-00026-538e1ac6-055e-4e72-9177-63daaaae1f98.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-02&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065074000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-02/part-00031-8a03451a-0297-4c43-b64d-56db25807d02.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-02&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065072000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
</code></pre></div><p>Alright, let&rsquo;s go ahead and update one of our rows. Delta Lake provides a merge operation that we can use. We&rsquo;ll use the syntax <a href=https://docs.delta.io/latest/quick-start.html#update-table-data>from the docs</a> that&rsquo;s slightly different from native Spark as it creates a DeltaTable object.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> pyspark.sql.functions <span style=color:#f92672>import</span> lit

<span style=color:#75715e># Create a new DataFrame from the first row of inputDF with a different creation_date value</span>
updateDF <span style=color:#f92672>=</span> inputDF<span style=color:#f92672>.</span>where(<span style=color:#e6db74>&#34;id = 100&#34;</span>)<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;creation_date&#34;</span>, lit(<span style=color:#e6db74>&#34;2022-01-11&#34;</span>))

<span style=color:#f92672>from</span> delta.tables <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>from</span> pyspark.sql.functions <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>

deltaTable <span style=color:#f92672>=</span> DeltaTable<span style=color:#f92672>.</span>forPath(spark, f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/delta/&#34;</span>)

deltaTable<span style=color:#f92672>.</span>alias(<span style=color:#e6db74>&#34;oldData&#34;</span>) \
  <span style=color:#f92672>.</span>merge(
    updateDF<span style=color:#f92672>.</span>alias(<span style=color:#e6db74>&#34;newData&#34;</span>),
    <span style=color:#e6db74>&#34;oldData.id = newData.id&#34;</span>) \
  <span style=color:#f92672>.</span>whenMatchedUpdate(set <span style=color:#f92672>=</span> { <span style=color:#e6db74>&#34;creation_date&#34;</span>: col(<span style=color:#e6db74>&#34;newData.creation_date&#34;</span>) }) \
  <span style=color:#f92672>.</span>execute()
</code></pre></div><p>Interestingly, now when we look at S3 we see 1 new <code>json</code> file and only 1 new <code>parquet</code> file (Remember Hudi and Iceberg both had 2 new <code>parquet</code> files).</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain>2022-01-24 23:05:46       1018 tmp/delta/_delta_log/00000000000000000001.json
2022-01-24 23:05:46        875 tmp/delta/creation_date=2022-01-11/part-00000-3f3fd83a-b876-4b6f-8f64-d8a4189392ae.c000.snappy.parquet
</code></pre></div><p>If we look at that new JSON file we see something really interesting:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>{
  <span style=color:#f92672>&#34;commitInfo&#34;</span>: {
    <span style=color:#f92672>&#34;timestamp&#34;</span>: <span style=color:#ae81ff>1643065545396</span>,
    <span style=color:#f92672>&#34;operation&#34;</span>: <span style=color:#e6db74>&#34;MERGE&#34;</span>,
    <span style=color:#f92672>&#34;operationParameters&#34;</span>: {
      <span style=color:#f92672>&#34;predicate&#34;</span>: <span style=color:#e6db74>&#34;(oldData.`id` = newData.`id`)&#34;</span>,
      <span style=color:#f92672>&#34;matchedPredicates&#34;</span>: <span style=color:#e6db74>&#34;[{\&#34;actionType\&#34;:\&#34;update\&#34;}]&#34;</span>,
      <span style=color:#f92672>&#34;notMatchedPredicates&#34;</span>: <span style=color:#e6db74>&#34;[]&#34;</span>
    },
    <span style=color:#f92672>&#34;readVersion&#34;</span>: <span style=color:#ae81ff>0</span>,
    <span style=color:#f92672>&#34;isBlindAppend&#34;</span>: <span style=color:#66d9ef>false</span>,
    <span style=color:#f92672>&#34;operationMetrics&#34;</span>: {
      <span style=color:#f92672>&#34;numTargetRowsCopied&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
      <span style=color:#f92672>&#34;numTargetRowsDeleted&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
      <span style=color:#f92672>&#34;numTargetFilesAdded&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
      <span style=color:#f92672>&#34;executionTimeMs&#34;</span>: <span style=color:#e6db74>&#34;4705&#34;</span>,
      <span style=color:#f92672>&#34;numTargetRowsInserted&#34;</span>: <span style=color:#e6db74>&#34;0&#34;</span>,
      <span style=color:#f92672>&#34;scanTimeMs&#34;</span>: <span style=color:#e6db74>&#34;3399&#34;</span>,
      <span style=color:#f92672>&#34;numTargetRowsUpdated&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
      <span style=color:#f92672>&#34;numOutputRows&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
      <span style=color:#f92672>&#34;numSourceRows&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
      <span style=color:#f92672>&#34;numTargetFilesRemoved&#34;</span>: <span style=color:#e6db74>&#34;1&#34;</span>,
      <span style=color:#f92672>&#34;rewriteTimeMs&#34;</span>: <span style=color:#e6db74>&#34;1265&#34;</span>
    }
  }
}
{
  <span style=color:#f92672>&#34;remove&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2015-01-01/part-00005-2e09dbe4-469e-40dc-9b36-833480f6d375.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;deletionTimestamp&#34;</span>: <span style=color:#ae81ff>1643065545378</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>,
    <span style=color:#f92672>&#34;extendedFileMetadata&#34;</span>: <span style=color:#66d9ef>true</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2015-01-01&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>
  }
}
{
  <span style=color:#f92672>&#34;add&#34;</span>: {
    <span style=color:#f92672>&#34;path&#34;</span>: <span style=color:#e6db74>&#34;creation_date=2022-01-11/part-00000-3f3fd83a-b876-4b6f-8f64-d8a4189392ae.c000.snappy.parquet&#34;</span>,
    <span style=color:#f92672>&#34;partitionValues&#34;</span>: {
      <span style=color:#f92672>&#34;creation_date&#34;</span>: <span style=color:#e6db74>&#34;2022-01-11&#34;</span>
    },
    <span style=color:#f92672>&#34;size&#34;</span>: <span style=color:#ae81ff>875</span>,
    <span style=color:#f92672>&#34;modificationTime&#34;</span>: <span style=color:#ae81ff>1643065546000</span>,
    <span style=color:#f92672>&#34;dataChange&#34;</span>: <span style=color:#66d9ef>true</span>
  }
}
</code></pre></div><p>In addition to the <code>operationMetrics</code> that gives us insight into how the data changed on &ldquo;disk&rdquo;, we also now see both a <code>remove</code> and <code>add</code> operation. In Delta Lake (and I&rsquo;m not quite sure why this happened yet&mldr;), each row was written to an individual <code>.parquet</code> file! So for this second version of the data, the fact that that row was updated simply lives in the metadata because it was the only row stored in that Parquet file. I&rsquo;m guessing this is simply because my dataset is so small the default number of partitions in Spark/Delta Lake resulted in this write configuration.</p><h2 id=snapshots>Snapshots<a hidden class=anchor aria-hidden=true href=#snapshots>#</a></h2><p>So now we&rsquo;ve got a good idea of the semantics of each of these storage layers. Let&rsquo;s take one more look at an important component of all of them and that&rsquo;s snapshots!</p><h3 id=hudi>Hudi<a hidden class=anchor aria-hidden=true href=#hudi>#</a></h3><p>Hudi has a concept of &ldquo;point-in-time&rdquo; queries where you provide it a range of two commit timestamps and it will show you what the data looked like at that point in time.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Query data from the first version of the table</span>
readOptions <span style=color:#f92672>=</span> {
  <span style=color:#e6db74>&#39;hoodie.datasource.query.type&#39;</span>: <span style=color:#e6db74>&#39;incremental&#39;</span>,
  <span style=color:#e6db74>&#39;hoodie.datasource.read.begin.instanttime&#39;</span>: <span style=color:#e6db74>&#39;0&#39;</span>,
  <span style=color:#e6db74>&#39;hoodie.datasource.read.end.instanttime&#39;</span>: <span style=color:#e6db74>&#39;20220114003341&#39;</span>,
}

incQueryDF <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read \
    <span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#39;org.apache.hudi&#39;</span>) \
    <span style=color:#f92672>.</span>options(<span style=color:#f92672>**</span>readOptions) \
    <span style=color:#f92672>.</span>load(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/hudi&#34;</span>)
    
incQueryDF<span style=color:#f92672>.</span>show()
</code></pre></div><h3 id=iceberg>Iceberg<a hidden class=anchor aria-hidden=true href=#iceberg>#</a></h3><p>Iceberg supports a similar mechanism called time travel and you can use either a <code>snapshot-id</code> or <code>as-of-timestamp</code> similar to Hudi.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># time travel to 2022-01-27 22:04:00 -0800</span>
df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read \
    <span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;as-of-timestamp&#34;</span>, <span style=color:#e6db74>&#34;1643349840000&#34;</span>) \
    <span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;iceberg&#34;</span>) \
    <span style=color:#f92672>.</span>load(ICEBERG_TABLE_NAME)
    
df<span style=color:#f92672>.</span>show()
</code></pre></div><h3 id=delta-lake-1>Delta Lake<a hidden class=anchor aria-hidden=true href=#delta-lake-1>#</a></h3><p>And, of course, Delta Lake supports this as well using either <a href=https://docs.delta.io/latest/delta-batch.html#-deltatimetravel>Spark SQL or DataFrames</a>. And similar to Iceberg you can use <code>versionAsOf</code> or <code>timestampAsOf</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># time travel to 2022-01-24 23:00</span>
df1 <span style=color:#f92672>=</span> (
    spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;delta&#34;</span>)
    <span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;timestampAsOf&#34;</span>, <span style=color:#e6db74>&#34;2022-01-24 23:00&#34;</span>)
    <span style=color:#f92672>.</span>load(f<span style=color:#e6db74>&#34;s3://{S3_BUCKET_NAME}/tmp/delta/&#34;</span>)
)
</code></pre></div><h2 id=deletes>Deletes<a hidden class=anchor aria-hidden=true href=#deletes>#</a></h2><p>I bet you&rsquo;re surprised I haven&rsquo;t mentioned deletes or GDPR yet. Don&rsquo;t worry&mldr;I will. 😀 But first I just wanted to understand exactly how these different systems work.</p><h2 id=wrapup>Wrapup<a hidden class=anchor aria-hidden=true href=#wrapup>#</a></h2><p>In this post, we reviewed the basics of Apache Hudi, Apache Iceberg, and Delta Lake - modern data lake storage layers. All these frameworks enable a set of functionality that optimize working with data in cloud-based object stores, albeit with slightly different approaches.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dacort.dev/tags/aws/>aws</a></li><li><a href=https://dacort.dev/tags/apache/>apache</a></li><li><a href=https://dacort.dev/tags/hudi/>hudi</a></li><li><a href=https://dacort.dev/tags/iceberg/>iceberg</a></li><li><a href=https://dacort.dev/tags/deltalake/>deltalake</a></li></ul><nav class=paginav><a class=next href=https://dacort.dev/posts/ssh-to-ec2-instances-with-session-manager/><span class=title>Next Page »</span><br><span>SSH to EC2 Instances with Session Manager</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share An Introduction to Modern Data Lake Storage Layers on twitter" href="https://twitter.com/intent/tweet/?text=An%20Introduction%20to%20Modern%20Data%20Lake%20Storage%20Layers&url=https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f&hashtags=aws%2capache%2chudi%2ciceberg%2cdeltalake"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Introduction to Modern Data Lake Storage Layers on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f&title=An%20Introduction%20to%20Modern%20Data%20Lake%20Storage%20Layers&summary=An%20Introduction%20to%20Modern%20Data%20Lake%20Storage%20Layers&source=https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Introduction to Modern Data Lake Storage Layers on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f&title=An%20Introduction%20to%20Modern%20Data%20Lake%20Storage%20Layers"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Introduction to Modern Data Lake Storage Layers on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Introduction to Modern Data Lake Storage Layers on whatsapp" href="https://api.whatsapp.com/send?text=An%20Introduction%20to%20Modern%20Data%20Lake%20Storage%20Layers%20-%20https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Introduction to Modern Data Lake Storage Layers on telegram" href="https://telegram.me/share/url?text=An%20Introduction%20to%20Modern%20Data%20Lake%20Storage%20Layers&url=https%3a%2f%2fdacort.dev%2fposts%2fmodern-data-lake-storage-layers%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://dacort.dev/>Damon Cortesi</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script><script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Python on Damon Cortesi</title><link>https://dacort.xyz/tags/python/</link><description>Recent content in Python on Damon Cortesi</description><generator>Hugo -- 0.153.2</generator><language>en-us</language><lastBuildDate>Wed, 14 Jul 2021 16:00:00 -0700</lastBuildDate><atom:link href="https://dacort.xyz/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Continuous Deployment of Jupyter Notebooks</title><link>https://dacort.xyz/posts/continuous-deployment-of-jupyter-notebooks/</link><pubDate>Wed, 14 Jul 2021 16:00:00 -0700</pubDate><guid>https://dacort.xyz/posts/continuous-deployment-of-jupyter-notebooks/</guid><description>&lt;p&gt;This is a guide on how to use AWS CodePipeline to continuously deploy Jupyter notebooks to an S3-backed static website.&lt;/p&gt;
&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;
&lt;p&gt;Since I started using &lt;a href="https://aws.amazon.com/emr/features/studio/"&gt;EMR Studio&lt;/a&gt;, I&amp;rsquo;ve been making more use of Jupyter notebooks as scratch pads and often want to be able to easily share the results of my research. I hunted around for a few different solutions and while there are some good ones like &lt;a href="https://nbconvert.readthedocs.io/en/latest/"&gt;nbconvert&lt;/a&gt; and &lt;a href="https://github.com/mwouts/jupytext/"&gt;jupytext&lt;/a&gt;, I wanted something a bit simpler and off-the-shelf. This post from &lt;a href="https://www.linkedin.com/in/mikkelhartmann/"&gt;Mikkel Hartmann&lt;/a&gt; about &lt;a href="http://mikkelhartmann.dk/2019/05/14/static-website-from-jupyter-notebooks.html"&gt;making a static website from Jupyter Notebooks&lt;/a&gt; led me to &lt;a href="https://www.mkdocs.org/"&gt;MkDocs&lt;/a&gt; and luckily, I came across &lt;a href="https://github.com/greenape/mknotebooks"&gt;mknotebooks&lt;/a&gt;, which offers a simple plugin for MkDocs. üòÖ&lt;/p&gt;</description><content:encoded><![CDATA[<p>This is a guide on how to use AWS CodePipeline to continuously deploy Jupyter notebooks to an S3-backed static website.</p>
<h2 id="overview">Overview</h2>
<p>Since I started using <a href="https://aws.amazon.com/emr/features/studio/">EMR Studio</a>, I&rsquo;ve been making more use of Jupyter notebooks as scratch pads and often want to be able to easily share the results of my research. I hunted around for a few different solutions and while there are some good ones like <a href="https://nbconvert.readthedocs.io/en/latest/">nbconvert</a> and <a href="https://github.com/mwouts/jupytext/">jupytext</a>, I wanted something a bit simpler and off-the-shelf. This post from <a href="https://www.linkedin.com/in/mikkelhartmann/">Mikkel Hartmann</a> about <a href="http://mikkelhartmann.dk/2019/05/14/static-website-from-jupyter-notebooks.html">making a static website from Jupyter Notebooks</a> led me to <a href="https://www.mkdocs.org/">MkDocs</a> and luckily, I came across <a href="https://github.com/greenape/mknotebooks">mknotebooks</a>, which offers a simple plugin for MkDocs. üòÖ</p>
<p>So, by using a simple static site generator that&rsquo;s geared toward project documentation, and a plugin that renders Jupyter notebooks quite well, and a few fancy code pipelines&hellip;I can easily push my notebooks to production. Let&rsquo;s go!</p>
<h2 id="architecture">Architecture</h2>
<p>This is the architecture we&rsquo;ll be implementing. This will all be built using the <a href="https://aws.amazon.com/cdk/">AWS Cloud Development Kit</a> (CDK).</p>
<p><img loading="lazy" src="/posts/continuous-deployment-of-jupyter-notebooks/jupyter_notebook_cd_architecture.png"></p>
<p>We&rsquo;ll be creating the following:</p>
<ul>
<li>2 S3 buckets to store our logs and website artifacts</li>
<li>A CodeCommmit repository that holds our site and notebooks</li>
<li>A CodeBuild project that generates the static site</li>
<li>A CodePipeline that is triggered by new commits, builds the site, and deploys it to S3</li>
<li>A CloudFront Distribution that serves the site</li>
<li>And optionally an ACM certificate if you want an alternate domain name</li>
</ul>
<p>I won&rsquo;t go into the details of the entire CDK stack, but instead will show how to deploy the CD pipeline.</p>
<h2 id="deploying">Deploying</h2>
<h3 id="pre-requisites">Pre-requisites</h3>
<p>You&rsquo;ll need to have <a href="https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html#getting_started_prerequisites">CDK installed</a> (&gt;= v1.107.0) and Python &gt;= 3.9.</p>
<p>I use <a href="https://github.com/nodenv/nodenv">nodenv</a> and <a href="https://virtualenv.pypa.io/en/latest/">virtualenv</a> for my respective environments.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># I use node 14.5.0</span>
</span></span><span style="display:flex;"><span>nodenv shell 14.5.0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># And Python3</span>
</span></span><span style="display:flex;"><span>virtualenv -p python3.8 .venv
</span></span><span style="display:flex;"><span>source .venv/bin/activate
</span></span></code></pre></div><h3 id="bootstrapping">Bootstrapping</h3>
<p>The source code is available in <a href="https://github.com/dacort/jupyter-static-website">dacort/jupyter-static-website</a>. In order to get started, we just need to clone that repo and deploy our CDK stack!</p>
<p>This project is a two-phased deploy due to the fact that CloudFront certificates need to be in <code>us-east-1</code>. If you <em>do not</em> need a custom domain, you can skip the first part.</p>
<p>First, clone the project and install the necessary requirements.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>git clone https://github.com/dacort/jupyter-static-website.git
</span></span><span style="display:flex;"><span>cd jupyter-static-website
</span></span><span style="display:flex;"><span>pip install -r requirements.txt
</span></span></code></pre></div><p>You&rsquo;ll also need to <a href="https://docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html">bootstrap</a> your AWS CDK environment in the account and region you want to deploy Part 2 in.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cdk bootstrap aws://ACCOUNT-NUMBER-1/REGION-1
</span></span></code></pre></div><h3 id="part-1---cloudfront-certificate">Part 1 - CloudFront Certificate</h3>
<p><em>If you are not using a custom domain, skip to Part 2</em></p>
<p>This project only supports using the default CloudFront certificate and a DNS-validated CNAME. In order to generate the certificate, you&rsquo;ll need to run the command below, go into the <a href="https://console.aws.amazon.com/acm/home?region=us-east-1#/">AWS Certificate Manager console</a> and make sure you follow the validation instructions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cdk deploy CloudfrontCertificateStack -c domain_name<span style="color:#f92672">=</span>notebooks.example.com
</span></span></code></pre></div><p>Once the domain is validated, the stack should finish provisioning.</p>
<p>One of the outputs from this stack will be <code>CloudfrontCertificateStack.certificatearn</code> - you&rsquo;ll need the value of this for the next phase.</p>
<h3 id="part-2---jupyter-cd-pipeline">Part 2 - Jupyter CD Pipeline</h3>
<p><em>If you are not using a custom domain, you can omit both of the <code>-c</code> options below.</em></p>
<p>If you want to deploy to a different region, make sure you set the <code>AWS_DEFAULT_REGION</code> environment variable.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cdk deploy EmrStudioPublisherStack <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    -c domain_name<span style="color:#f92672">=</span>notebooks.example.com <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    -c certificate_arn<span style="color:#f92672">=</span>arn:aws:acm:us-east-1:012345678912:certificate/f07b01a4-3e8c-4639-8a22-b7a20a832de3
</span></span></code></pre></div><p>Once this stack finishes, you should have a CodeCommit repository you can make changes to, a CloudFront distribution, and a publicly accessible URL (found in the <code>EmrStudioPublisherStack.cloudfrontendpoint</code> output) that has a pre-populated example site.</p>
<p>The site will take a few minutes to deploy - you&rsquo;ll be able to keep an eye on the status in the <a href="https://console.aws.amazon.com/codesuite/codepipeline/pipelines">CodePipeline console</a>.</p>
<h2 id="usage">Usage</h2>
<p>Usage is pretty straight-forward. <code>git clone</code> the repository, add a new notebook, and push it back up! If you&rsquo;re using EMR Studio, you can add your CodeCommit repository and make your changes to your Jupyter notebooks there.</p>
<p>I made a video about <a href="https://www.youtube.com/watch?v=ZdbUTxBjBIs">connecting to Git in EMR Studio</a> that you might find useful.</p>
<p>Any new notebooks added in the <code>site/docs/notebooks/</code> directory will automatically be published.</p>
<p>You can add links to the notebooks by updating the <code>nav</code> section of the <code>mkdocs.yml</code> file.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">nav</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">Home</span>: <span style="color:#ae81ff">index.md</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">Notebooks</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">Oura Sleep Analysis</span>: <span style="color:#ae81ff">notebooks/damons_sleep.ipynb</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">Intro to Data Processing on AWS</span>: <span style="color:#ae81ff">notebooks/intro_data_processing_aws.ipynb</span>
</span></span></code></pre></div><p>This YAML config will generate a nav dropdown like so.</p>
<p><img alt="Navigation example" loading="lazy" src="/posts/continuous-deployment-of-jupyter-notebooks/nav_dropdown.png"></p>
<h3 id="advanced-usage">Advanced Usage</h3>
<p>Note that not <em>all</em> images or libraries render nicely when converting to HTML. This is why, for example, in my plotly example I had to use <code>fig.show(renderer=&quot;jupyterlab&quot;)</code></p>
<p>In addition, if you paste multiple images into your notebook&rsquo;s Markdown, mknotebooks <a href="https://github.com/greenape/mknotebooks/issues/466">only renders one of them</a>. In order to work around this, I added a pre-build step that uniquify&rsquo;s all the image attachments in Markdown cells.</p>
]]></content:encoded></item><item><title>Big Data Stack with CDK</title><link>https://dacort.xyz/posts/cdk-big-data-stack/</link><pubDate>Fri, 18 Jun 2021 21:59:00 -0700</pubDate><guid>https://dacort.xyz/posts/cdk-big-data-stack/</guid><description>How I built my own Apache Spark environment on AWS using Amazon EMR, Amazon EKS, and the AWS Cloud Development Kit (CDK).</description><content:encoded><![CDATA[<p>I wanted to write a post about how I built my own Apache Spark environment on AWS using Amazon EMR, Amazon EKS, and the AWS Cloud Development Kit (CDK). This stack also creates an EMR Studio environment that can be used to build and deploy data notebooks.</p>
<p><em>Disclaimer: I work for AWS on the EMR team and built this stack for my <a href="https://www.youtube.com/channel/UCKtlXVZC2DqzayRlZYLObZw">various demos</a> and it is not intended for production use-cases.</em> üôè</p>
<p>Also note that the commands below are for demonstration purposes only, the full code is available in my <a href="https://github.com/dacort/demo-code/tree/main/cdk/big-data-stack">demo-code/cdk/big-data-stack</a> repository.</p>
<h2 id="overview">Overview</h2>
<p>At re:Invent 2020, AWS introduced EMR on EKS - a way to run Apache Spark workloads on Kubernetes using managed services. Once you&rsquo;re up and running, you can submit a Spark job to EMR on EKS with a single AWS CLI command. But provisioning EKS, ensuring it has all the necessary resources to run your jobs, creating IAM roles and Kubernetes service accounts, and linking those back to EMR can be a lot of manual effort. Using AWS CDK, we can easily provision the entire stack:</p>
<ul>
<li>A VPC in 3 availability zones</li>
<li>An EKS cluster with the following addons
<ul>
<li>Cluster Autoscaler</li>
<li>Kubernetes Dashboard</li>
</ul>
</li>
<li>An EMR virtual cluster connected to our EKS cluster</li>
<li>An EMR Studio environment
<ul>
<li>A Service Catalog cluster template</li>
</ul>
</li>
</ul>
<p>This is the high-level architecture of what the resulting stack will look like. Now let&rsquo;s walk through each different piece.</p>
<p><img alt="CDK Big Data Stack architecture" loading="lazy" src="/images/cdk-big-data-stack-arch.png"></p>
<h2 id="vpc">VPC</h2>
<p>This is probably the easiest part of the whole setup. In CDK, you can provision a VPC with the following code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> aws_cdk <span style="color:#f92672">import</span> aws_ec2 <span style="color:#66d9ef">as</span> ec2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ec2<span style="color:#f92672">.</span>Vpc(self, <span style="color:#e6db74">&#34;EMRDemos&#34;</span>, max_azs<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span></code></pre></div><p>And you&rsquo;re done. üéâ In my stack, I make the resulting <code>ec2.Vpc</code> object an attribute on the VPC stack so I can use it in other parts of my stack.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>app <span style="color:#f92672">=</span> cdk<span style="color:#f92672">.</span>App()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vpc <span style="color:#f92672">=</span> VPCStack(app, <span style="color:#e6db74">&#34;VPCStack&#34;</span>)
</span></span><span style="display:flex;"><span>eks <span style="color:#f92672">=</span> EKSStack(app, <span style="color:#e6db74">&#34;EKSStack&#34;</span>, vpc<span style="color:#f92672">.</span>vpc)
</span></span><span style="display:flex;"><span>emr_containers <span style="color:#f92672">=</span> EMRContainersStack(app, <span style="color:#e6db74">&#34;EMRContainers&#34;</span>, vpc<span style="color:#f92672">.</span>vpc, eks<span style="color:#f92672">.</span>cluster)
</span></span><span style="display:flex;"><span>emr_studio <span style="color:#f92672">=</span> EMRStudio(app, <span style="color:#e6db74">&#34;EMRStudio&#34;</span>, vpc<span style="color:#f92672">.</span>vpc, <span style="color:#e6db74">&#34;big-data-studio&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>app<span style="color:#f92672">.</span>synth()
</span></span></code></pre></div><p>Let&rsquo;s walk through what happens in each of these stacks.</p>
<h2 id="eksstack">EKSStack</h2>
<p>This one is a little more complex. In many cases, you only need to stand up your EKS cluster once and you&rsquo;ll use that in perpetuity. But there certainly are cases where you might provision multiple EKS stacks for security or organizational reasons. Provisioning an EKS stack in CDK is relatively straightforward.</p>
<ul>
<li>First, provision the EKS Cluster</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> aws_cdk <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    aws_eks <span style="color:#66d9ef">as</span> eks,
</span></span><span style="display:flex;"><span>    aws_ec2 <span style="color:#66d9ef">as</span> ec2,
</span></span><span style="display:flex;"><span>    aws_iam <span style="color:#66d9ef">as</span> iam,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cluster <span style="color:#f92672">=</span> eks<span style="color:#f92672">.</span>Cluster(
</span></span><span style="display:flex;"><span>    self,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;EksForSpark&#34;</span>,
</span></span><span style="display:flex;"><span>    cluster_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;data-team&#34;</span>,
</span></span><span style="display:flex;"><span>    version<span style="color:#f92672">=</span>eks<span style="color:#f92672">.</span>KubernetesVersion<span style="color:#f92672">.</span>V1_19,
</span></span><span style="display:flex;"><span>    default_capacity<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    endpoint_access<span style="color:#f92672">=</span>eks<span style="color:#f92672">.</span>EndpointAccess<span style="color:#f92672">.</span>PUBLIC_AND_PRIVATE,
</span></span><span style="display:flex;"><span>    vpc<span style="color:#f92672">=</span>vpc,
</span></span><span style="display:flex;"><span>    vpc_subnets<span style="color:#f92672">=</span>[ec2<span style="color:#f92672">.</span>SubnetSelection(subnet_type<span style="color:#f92672">=</span>ec2<span style="color:#f92672">.</span>SubnetType<span style="color:#f92672">.</span>PRIVATE)],
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><ul>
<li>Then, add one or more <a href="https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html">managed node groups</a>.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>nodegroup <span style="color:#f92672">=</span> cluster<span style="color:#f92672">.</span>add_nodegroup_capacity(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;base-node-group&#34;</span>,
</span></span><span style="display:flex;"><span>    instance_types<span style="color:#f92672">=</span>[ec2<span style="color:#f92672">.</span>InstanceType(<span style="color:#e6db74">&#34;m5.xlarge&#34;</span>)],     <span style="color:#75715e"># You could add additional instance types here</span>
</span></span><span style="display:flex;"><span>    min_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,                                         <span style="color:#75715e"># The node group can scale to 1</span>
</span></span><span style="display:flex;"><span>    max_size<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>,                                        <span style="color:#75715e"># And up to 20 nodes</span>
</span></span><span style="display:flex;"><span>    disk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,                                       <span style="color:#75715e"># Give each node 50gb of disk</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><ul>
<li>You&rsquo;ll also likely want to grant an IAM role admin access to the cluster</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>admin_iam_role_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Admin&#34;</span>           <span style="color:#75715e"># This role must already exist in your AWS account</span>
</span></span><span style="display:flex;"><span>account_id <span style="color:#f92672">=</span> cdk<span style="color:#f92672">.</span>Aws<span style="color:#f92672">.</span>ACCOUNT_ID
</span></span><span style="display:flex;"><span>admin_role <span style="color:#f92672">=</span> iam<span style="color:#f92672">.</span>Role<span style="color:#f92672">.</span>from_role_arn(
</span></span><span style="display:flex;"><span>    self, <span style="color:#e6db74">&#34;admin_role&#34;</span>, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;arn:aws:iam::</span><span style="color:#e6db74">{</span>account_id<span style="color:#e6db74">}</span><span style="color:#e6db74">:role/</span><span style="color:#e6db74">{</span>admin_role_name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>cluster<span style="color:#f92672">.</span>aws_auth<span style="color:#f92672">.</span>add_masters_role(admin_role)
</span></span></code></pre></div><h3 id="cluster-autoscaler">Cluster Autoscaler</h3>
<p>Finally, a critical component to install is the <a href="https://docs.aws.amazon.com/eks/latest/userguide/cluster-autoscaler.html">Cluster Autoscaler</a>. The EKS documentation shows how to deploy it using the <code>kubectl</code> command, but I wanted to wrap this up in the CDK stack. I also ran into <a href="https://github.com/kubernetes/autoscaler/issues/3901">this issue</a> where a Helm chart for 1.19 doesn&rsquo;t exist. üôÅ.</p>
<p>So I created an <a href="https://github.com/dacort/demo-code/blob/main/cdk/big-data-stack/plugins/eks/autoscaler.py">autoscaler module</a> that I can easily apply to my cluster and node groups.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cluster_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data-team&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ClusterAutoscaler(
</span></span><span style="display:flex;"><span>    cluster_name, self, cluster, [nodegroup]
</span></span><span style="display:flex;"><span>)<span style="color:#f92672">.</span>enable_autoscaling()
</span></span></code></pre></div><p>This code performs the following steps in order to enable the cluster autoscaler on an EKS cluster:</p>
<ul>
<li>Adds tags to the passed node groups to enable auto discovery</li>
<li>Creates a new IAM Role that can change Auto Scaling Groups</li>
<li>Creates a Kubernetes service account</li>
<li>Creates a new cluster-autoscaler deployment</li>
<li>Creates the corresponding rbac rules</li>
</ul>
<h3 id="kubernetes-dashboard">Kubernetes Dashboard</h3>
<p>The Kubernetes Dashboard is also extremely valuable to be able to examine what&rsquo;s happening in your EKS cluster. It&rsquo;s easy to install by using the CDK <code>add_helm_chart</code> functionality.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>chart <span style="color:#f92672">=</span> cluster<span style="color:#f92672">.</span>add_helm_chart(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;kubernetes-dashboard&#34;</span>,
</span></span><span style="display:flex;"><span>    namespace<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;kubernetes-dashboard&#34;</span>,
</span></span><span style="display:flex;"><span>    chart<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;kubernetes-dashboard&#34;</span>,
</span></span><span style="display:flex;"><span>    repository<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://kubernetes.github.io/dashboard/&#34;</span>,
</span></span><span style="display:flex;"><span>    values<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;fullnameOverride&#34;</span>: <span style="color:#e6db74">&#34;kubernetes-dashboard&#34;</span>,  <span style="color:#75715e"># This must be set to acccess the UI via `kubectl proxy`</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;extraArgs&#34;</span>: [<span style="color:#e6db74">&#34;--token-ttl=0&#34;</span>],              <span style="color:#75715e"># This prevents your access token from expiring, but is not intended for a production environment</span>
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>üíÅ Note that I&rsquo;m setting <code>--token-ttl=0</code> so I don&rsquo;t have to re-sign in to the Dashboard every 10(!) minutes, but you shouldn&rsquo;t use this in a production environment. There&rsquo;s some more info about <a href="https://blinkeye.github.io/post/public/2019-05-30-kubernetes-dashboard/">adjusting the timeout the dashboard here</a>.</p>
<h2 id="emrcontainersstack">EMRContainersStack</h2>
<p>A pre-requisite to running EMR on EKS is that you have to map the <code>AWSServiceRoleForAmazonEMRContainers</code> role to the EKS cluster. In order to prevent a circular dependency, I ended up doing this in the EKS stack.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>service_role_name <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;arn:aws:iam::</span><span style="color:#e6db74">{</span>cdk<span style="color:#f92672">.</span>Aws<span style="color:#f92672">.</span>ACCOUNT_ID<span style="color:#e6db74">}</span><span style="color:#e6db74">:role/AWSServiceRoleForAmazonEMRContainers&#34;</span>
</span></span><span style="display:flex;"><span>emrsvcrole <span style="color:#f92672">=</span> iam<span style="color:#f92672">.</span>Role<span style="color:#f92672">.</span>from_role_arn(
</span></span><span style="display:flex;"><span>    self, <span style="color:#e6db74">&#34;EmrSvcRole&#34;</span>, service_role_name, mutable<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>cluster<span style="color:#f92672">.</span>aws_auth<span style="color:#f92672">.</span>add_role_mapping(
</span></span><span style="display:flex;"><span>    emrsvcrole, groups<span style="color:#f92672">=</span>[], username<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;emr-containers&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><a href="https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/setting-up.html">Setting up EMR on EKS</a> requires several steps:</p>
<ul>
<li>Create a namespace for EMR to use</li>
<li>Create a k8s cluster role for EMR</li>
<li>Bind the cluster role to the <code>emr-containers</code> user we created above</li>
<li>Create a (nicely-named) job execution role</li>
<li>And then create our EMR virtual cluster</li>
</ul>
<p>If you want to <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-create-eks-cluster.html">use EMR Studio with EMR on EKS</a>, you can also (optionally) create a managed endpoint. I don&rsquo;t quite have this fully automated with CDK yet.</p>
<p>I won&rsquo;t detail the whole setup here because it&rsquo;s about 400 lines of Python code, but you can see my <a href="https://github.com/dacort/demo-code/blob/main/cdk/big-data-stack/stacks/eks.py">EMR on EKS Stack</a> on GitHub.</p>
<p>‚ö†Ô∏è One thing to call out is that inside the <code>create_job_execution_role</code> method, we create a new job role we can use to run our jobs on EMR on EKS. This role is, admittedly, way overscoped and allows full access to S3, EC2, Glue, and CloudWatch. It is heavily recommended that you scope down the permissions this role has.</p>
<h2 id="emrstudio">EMRStudio</h2>
<p><a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-set-up.html">Setting up EMR Studio</a> requires the creation of several Studio-specific IAM roles, an S3 bucket for Studio assets, and mapping an AWS SSO user to the Studio.</p>
<p>The <code>EMRStudio</code> stack performs all these steps as well as tagging the provided VPC with <code>for-use-with-amazon-emr-managed-policies=true</code> so that if you&rsquo;re creating EMR clusters from Studio, the necessary resources can be created.</p>
<p>If you&rsquo;re creating a Studio environment from scratch, there is also an <a href="https://github.com/aws-samples/emr-studio-samples">EMR Studio Samples</a> GitHub repository that provides CloudFormation templates for creating an environment as well as a sample Apache Airflow DAG for triggering EMR on EKS jobs.</p>
<p>I won&rsquo;t dive too deep into this because it&rsquo;s again about 600 lines of Python code (largely IAM policies), but this is the CDK code that creates the EMR Studio.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>studio <span style="color:#f92672">=</span> emr<span style="color:#f92672">.</span>CfnStudio(
</span></span><span style="display:flex;"><span>    self,
</span></span><span style="display:flex;"><span>    construct_id,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span>name,
</span></span><span style="display:flex;"><span>    auth_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;SSO&#34;</span>,
</span></span><span style="display:flex;"><span>    vpc_id<span style="color:#f92672">=</span>vpc<span style="color:#f92672">.</span>vpc_id,
</span></span><span style="display:flex;"><span>    default_s3_location<span style="color:#f92672">=</span>studio_bucket<span style="color:#f92672">.</span>s3_url_for_object(),
</span></span><span style="display:flex;"><span>    engine_security_group_id<span style="color:#f92672">=</span>engine_sg<span style="color:#f92672">.</span>security_group_id,
</span></span><span style="display:flex;"><span>    workspace_security_group_id<span style="color:#f92672">=</span>workspace_sg<span style="color:#f92672">.</span>security_group_id,
</span></span><span style="display:flex;"><span>    service_role<span style="color:#f92672">=</span>service_role<span style="color:#f92672">.</span>role_arn,
</span></span><span style="display:flex;"><span>    user_role<span style="color:#f92672">=</span>user_role<span style="color:#f92672">.</span>role_arn,
</span></span><span style="display:flex;"><span>    subnet_ids<span style="color:#f92672">=</span>vpc<span style="color:#f92672">.</span>select_subnets()<span style="color:#f92672">.</span>subnet_ids,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="deploying">Deploying</h2>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>Node &gt;=14.x and <a href="https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html">CDK</a></li>
<li>Python &gt;= 3.9 and <a href="https://docs.python-guide.org/dev/virtualenvs/#lower-level-virtualenv">virtualenv</a></li>
<li>An IAM role you want to grant admin access to EKS</li>
<li><a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-enable-sso.html">AWS SSO configured</a> in the AWS Region where you are deploying
<ul>
<li>A user in SSO you want to grant access to EMR Studio</li>
</ul>
</li>
<li><a href="https://kubernetes.io/docs/tasks/tools/">kubectl</a> if you wish to access the Kubernetes Dashboard</li>
</ul>
<h3 id="setup">Setup</h3>
<ul>
<li>Clone my <a href="https://github.com/dacort/demo-code"><code>demo-code</code></a> repository and <code>cd</code> into the <code>cdk/big-data-stack</code> directory</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>git clone https://github.com/dacort/demo-code.git
</span></span><span style="display:flex;"><span>cd demo-code/cdk/big-data-stack
</span></span></code></pre></div><ul>
<li>Create a Python virtualenv and install the necessary dependencies</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>virtualenv -p python3 .venv
</span></span><span style="display:flex;"><span>source .venv/bin/activate
</span></span><span style="display:flex;"><span>pip install -r requirements.txt
</span></span></code></pre></div><h3 id="deploy">Deploy</h3>
<ul>
<li>Bootstrap CDK for the AWS account and Region you want to deploy in</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cdk bootstrap aws://account/region
</span></span></code></pre></div><ul>
<li>Deploy your big data stack!
<ul>
<li><code>eks_admin_role_name</code> is the IAM role you want to have admin access to EKS</li>
<li><code>studio_admin_user_name</code> is the AWS SSO user you want to grant access to EMR Studio</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cdk deploy --all -c eks_admin_role_name<span style="color:#f92672">=</span>Admin -c studio_admin_user_name<span style="color:#f92672">=</span>dacort
</span></span></code></pre></div><p>This will synthesize your stack into a set of CloudFormation templates and then roll out each piece of the stack.</p>
<p>If everything goes well, you should get a set of big green checkmarks!</p>
<p>Each stack may also print out a set of &ldquo;Outputs&rdquo; and there are three in particular I want to highlight.</p>
<ol>
<li><code>EMRContainers.EMRVirtualClusterID = abcdefghijklmno1234567890</code></li>
</ol>
<p>This is the ID of your EMR virtual cluster - you&rsquo;ll need this to run jobs.</p>
<ol>
<li><code>EMRContainers.JobRoleArn = arn:aws:iam::012345678912:role/emr_eks_default_role</code></li>
</ol>
<p>This is the IAM role created in the <code>EMRContainers</code> stack that you can use to run your EMR on EKS jobs.</p>
<ol start="2">
<li><code>EKSStack.EksForSparkConfigCommandABCD1234 = aws eks update-kubeconfig --name data-team --region us-east-2 --role-arn arn:aws:iam::012345678912:role/EKSStack-EksForSparkMastersRoleABCD1234-ABCDEF123456</code></li>
</ol>
<p>This is the command you can use to add the new EKS cluster to your kubeconfig file so you can use <code>kubectl</code> commands.</p>
<h3 id="access-the-kubernetes-dashboard">Access the Kubernetes Dashboard</h3>
<p>We want to be able to inspect pods and other resources on our clusters. In order to do that, we need to use <code>kubectl</code> to proxy location connections to the EKS cluster.</p>
<p>First, run the command in the <code>EKSStack.EksForSparkConfigCommandABCD1234</code> output above. Then, use <code>kubectl proxy</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>‚ûú kubectl proxy
</span></span><span style="display:flex;"><span>Starting to serve on 127.0.0.1:8001
</span></span></code></pre></div><p>Next, fetch a token that you can use to login to the Dashboard.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>SECRET_NAME<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl -n kube-system get secret | grep eks-admin | awk <span style="color:#e6db74">&#39;{print $1}&#39;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>TOKEN<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>kubectl -n kube-system describe secret $SECRET_NAME | grep -E <span style="color:#e6db74">&#39;^token&#39;</span> | cut -f2 -d<span style="color:#e6db74">&#39;:&#39;</span> | tr -d <span style="color:#e6db74">&#34; &#34;</span><span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>echo $TOKEN
</span></span></code></pre></div><p>Copy the value that&rsquo;s output, open up the following URL in your browser, and paste the token where it says &ldquo;Enter token *&rdquo;</p>
<p><a href="http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:https/proxy/#!/login">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:https/proxy/#!/login</a></p>
<p><img loading="lazy" src="/posts/cdk-big-data-stack/k8s-dashboard-login.png"></p>
<blockquote>
<p>A quick note about the URL above. It is constructed dynamically from the namespace and service names used in the kubernetes-dashboard helm chart. We&rsquo;ve defined the <code>fullnameOverride</code> value in the config for that chart or else the service name would be dynamic.</p>
</blockquote>
<p>Now that you&rsquo;re logged in, you should be able to browse to the &ldquo;Pods&rdquo; section and select <code>emr-jobs</code> from the namespace dropdown next to the search box. You won&rsquo;t have any pods yet, but they&rsquo;ll show up there when you run a job.</p>
<h3 id="run-a-job">Run a job</h3>
<p>With everything all deployed, you should be able to run a sample job through EMR on EKS.</p>
<blockquote>
<p>Note that the values of <code>virtual-cluster-id</code> and <code>execution-role-arn</code> can be obtained from the values output by your <code>cdk deploy command</code></p>
</blockquote>
<pre tabindex="0"><code>EMRContainers.EMRVirtualClusterID = abcdefghijklmno1234567890
EMRContainers.JobRoleArn = arn:aws:iam::012345678912:role/emr_eks_default_role
</code></pre><p>Take those values and replace in the job below!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>export EMR_EKS_CLUSTER_ID<span style="color:#f92672">=</span>&lt;EMRVirtualClusterID&gt;
</span></span><span style="display:flex;"><span>export EMR_EKS_EXECUTION_ARN<span style="color:#f92672">=</span>&lt;JobRoleArn&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>aws emr-containers start-job-run <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    --virtual-cluster-id <span style="color:#e6db74">${</span>EMR_EKS_CLUSTER_ID<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    --name pi-test <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    --execution-role-arn <span style="color:#e6db74">${</span>EMR_EKS_EXECUTION_ARN<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    --release-label emr-6.3.0-latest <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span>    --job-driver <span style="color:#e6db74">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;sparkSubmitJobDriver&#34;: {
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;entryPoint&#34;: &#34;local:///usr/lib/spark/examples/src/main/python/pi.py&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;sparkSubmitParameters&#34;: &#34;--conf spark.executor.instances=1 --conf spark.executor.memory=2G --conf spark.executor.cores=1 --conf spark.driver.cores=1&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        }
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    }&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;id&#34;</span>: <span style="color:#e6db74">&#34;0000000abcdef123456&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;pi-test&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;arn&#34;</span>: <span style="color:#e6db74">&#34;arn:aws:emr-containers:us-east-2:012345678912:/virtualclusters/abcdefghijklmno1234567890/jobruns/0000000abcdef123456&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;virtualClusterId&#34;</span>: <span style="color:#e6db74">&#34;abcdefghijklmno1234567890&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="wrapup">Wrapup</h2>
<p>Take a look at my <a href="https://www.youtube.com/watch?v=2UMz72NRZss&amp;list=PLUe6KRx8LhLpJ8CyNHewFYukWm7sQyQrM">EMR on EKS playlists</a> for more examples.</p>
<p>And if you installed the EMR Studio stack, you can see your Studio URL in the <code>EMRStudio.EMRStudioURL</code> variable, or you can list your Studios and the access URL via the <code>aws emr list-studios</code> command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>aws emr list-studios
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;Studios&#34;</span>: [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;StudioId&#34;</span>: <span style="color:#e6db74">&#34;es-01234567890ABCDEFGHIJKLMN&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Name&#34;</span>: <span style="color:#e6db74">&#34;big-data-studio&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;VpcId&#34;</span>: <span style="color:#e6db74">&#34;vpc-abcdef012345678901&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Url&#34;</span>: <span style="color:#e6db74">&#34;https://es-01234567890ABCDEFGHIJKLMN.emrstudio-prod.us-east-1.amazonaws.com&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;CreationTime&#34;</span>: <span style="color:#e6db74">&#34;2021-06-02T16:20:56.548000-07:00&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>]]></content:encoded></item></channel></rss>